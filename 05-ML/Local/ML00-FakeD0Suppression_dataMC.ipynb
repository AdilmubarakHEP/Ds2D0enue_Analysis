{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall -y scikit-learn\n",
    "# !pip install scikit-learn==1.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install --upgrade pip\n",
    "# ! pip install --user xgboost seaborn\n",
    "# ! pip install --user bayesian-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mplhep\n",
    "import sys\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import uproot\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.datasets import make_classification,make_regression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import auc,roc_curve,confusion_matrix,classification_report,precision_recall_curve,mean_squared_error,accuracy_score,roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV, cross_validate, validation_curve,train_test_split,KFold,learning_curve,cross_val_score\n",
    "from sklearn.utils import compute_sample_weight\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from scipy.stats import randint, uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\n",
    "    \"axes.labelsize\": 16,\n",
    "    \"xtick.labelsize\": 12,\n",
    "    \"ytick.labelsize\": 12,\n",
    "    \"legend.fontsize\": 14,\n",
    "    \"figure.titlesize\": 20\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 200000)\n",
    "pd.set_option('display.max_columns', 200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/home/belle2/amubarak/Ds2D0enue_Analysis/07-Python_Functions/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep-Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incorrect Charge\n",
    "- This is the only sample that has the $D^{0}$ tree now. It should not matter to save it for the other control samples or the other samples in general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import uproot\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Configuration ===\n",
    "DataFrames = {}\n",
    "samples_WCh = [\n",
    "    \"Signal_WCh\", \"BB_WCh\", \"ccbar_WCh\", \"ddbar_WCh\",\n",
    "    \"ssbar_WCh\", \"taupair_WCh\", \"uubar_WCh\", \"Data_WCh\"\n",
    "]\n",
    "Date_WCh = \"0630\"\n",
    "Attempt_WCh = \"0\"\n",
    "\n",
    "# === Load one sample at a time ===\n",
    "for sample in tqdm(samples_WCh, desc=\"Loading WCh samples\"):\n",
    "    if sample == \"Signal_WCh\":\n",
    "        path = \"/home/belle2/amubarak/C01-Simulated_Events/Ds2D0enu-Signal_WCh.root:D02kmpiptree\"\n",
    "    else:\n",
    "        path = f\"/group/belle/users/amubarak/02-Grid/Sample_Grid_WCh/Ds2D0e-Generic_Ds_{Date_WCh}25_{Attempt_WCh}_{sample}.root:D02kmpiptree\"\n",
    "\n",
    "    try:\n",
    "        df = uproot.concatenate(path, library='pd')\n",
    "        DataFrames[sample] = df\n",
    "        print(f\"✔️ Loaded: {path} [{len(df):,} entries]\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed: {sample} — {e}\")\n",
    "\n",
    "# === Combine wrong-charge backgrounds ===\n",
    "background_WCh = [\"BB_WCh\", \"ccbar_WCh\", \"ddbar_WCh\", \"ssbar_WCh\", \"taupair_WCh\", \"uubar_WCh\"]\n",
    "DataFrames[\"All_WCh\"] = pd.concat([DataFrames[s] for s in background_WCh], ignore_index=True)\n",
    "DataFrames[\"uds_WCh\"] = pd.concat(\n",
    "    [DataFrames[s] for s in [\"uubar_WCh\", \"ddbar_WCh\", \"ssbar_WCh\"]],\n",
    "    ignore_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The line below is to look at the available variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(DataFrames.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrames[\"All_WCh\"].columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "The code below will be used to apply cuts to the data.  \n",
    "The range of the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Electron ID\n",
    "#-------------------\n",
    "# DataFrames[\"Signal\"] = DataFrames[\"Signal\"][DataFrames[\"Signal\"]['e_electronID']>=0.95]\n",
    "# DataFrames[\"ccbar\"] = DataFrames[\"ccbar\"][DataFrames[\"ccbar\"]['e_electronID']>=0.95]\n",
    "# DataFrames[\"Signal\"] = DataFrames[\"Signal\"][DataFrames[\"Signal\"]['Ds_gammaveto_em_electronID']>=0.95]\n",
    "# DataFrames[\"ccbar\"] = DataFrames[\"ccbar\"][DataFrames[\"ccbar\"]['Ds_gammaveto_em_electronID']>=0.95]\n",
    "\n",
    "# Photon Conversion\n",
    "#-------------------\n",
    "# DataFrames[samples[0]] = DataFrames[samples[0]][DataFrames[samples[0]]['Ds_gammaveto_M_Correction']>=0.1]\n",
    "# DataFrames[samples[1]] = DataFrames[samples[1]][DataFrames[samples[1]]['Ds_gammaveto_M_Correction']>=0.1]\n",
    "\n",
    "# Peaking Background Removal\n",
    "#----------------------------\n",
    "# DataFrames[\"ccbar\"] = DataFrames[\"ccbar\"][(DataFrames[\"ccbar\"]['Ds_diff_D0pi']>=0.15)]\n",
    "# DataFrames[\"Signal\"] = DataFrames[\"Signal\"][(DataFrames[\"Signal\"]['Ds_diff_D0pi']>=0.15)]\n",
    "\n",
    "# # Vertex Fitting\n",
    "# #----------------\n",
    "# DataFrames[\"Signal\"] = DataFrames[\"Signal\"][DataFrames[\"Signal\"]['Ds_chiProb']>=0.01]\n",
    "# DataFrames[\"ccbar\"] = DataFrames[\"ccbar\"][DataFrames[\"ccbar\"]['Ds_chiProb']>=0.01]\n",
    "\n",
    "# Dalitz Removal\n",
    "#----------------------------\n",
    "# DataFrames[\"ccbar\"] = DataFrames[\"ccbar\"][(DataFrames[\"ccbar\"]['Ds_pi0veto_M_Correction']<=0.08) | (DataFrames[\"ccbar\"]['Ds_pi0veto_M_Correction']>=0.16)]\n",
    "# DataFrames[\"Signal\"] = DataFrames[\"Signal\"][(DataFrames[\"Signal\"]['Ds_pi0veto_M_Correction']<=0.08) | (DataFrames[\"Signal\"]['Ds_pi0veto_M_Correction']>=0.16)]\n",
    "\n",
    "# Vertex Fit\n",
    "#----------------\n",
    "# DataFrames[samples[0]] = DataFrames[samples[0]][DataFrames[samples[0]]['Ds_chiProb_rank']==1]\n",
    "# DataFrames[samples[1]] = DataFrames[samples[1]][DataFrames[samples[1]]['Ds_chiProb_rank']==1]\n",
    "\n",
    "# D0 Invariant Mass\n",
    "#-----------------------\n",
    "# DataFrames[samples[0]] = DataFrames[samples[0]][(DataFrames[samples[0]]['Ds_D0_sideband']==1)]\n",
    "# DataFrames[samples[1]] = DataFrames[samples[1]][(DataFrames[samples[1]]['Ds_D0_sideband']==1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake $D^0$ Suppression\n",
    "data/MC Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === Settings ===\n",
    "bins = 50\n",
    "density = False\n",
    "figsize = (7, 7)\n",
    "\n",
    "# === Luminosity Scaling ===\n",
    "lum_data = 364.093   # fb⁻¹\n",
    "lum_MC = 1443.999    # fb⁻¹\n",
    "scale_factor = lum_data / lum_MC\n",
    "\n",
    "# === Correct Input Variables and Labels ===\n",
    "Variables = [\n",
    "    'K_kmpip_abs_dr',\n",
    "    'pi_kmpip_abs_dr',\n",
    "    'K_kmpip_kaonID',\n",
    "    'pi_kmpip_pionID',\n",
    "    'D0_kmpip_dM',\n",
    "    'D0_kmpip_chiProb',\n",
    "    'D0_kmpip_flightDistance',\n",
    "    'D0_kmpip_useCMSFrame_p',\n",
    "    'D0_kmpip_cos_decayAngle_1',\n",
    "]\n",
    "\n",
    "features = [\n",
    "    r'$dr(K^{-})\\;[\\mathrm{cm}]$',\n",
    "    r'$dr(\\pi^{+})\\;[\\mathrm{cm}]$',\n",
    "    r'$kaonID(K^{-})$',\n",
    "    r'$pionID(\\pi^{+})$',\n",
    "    r'$m(D^{0}) - m_{PDG}(D^{0})\\;[\\mathrm{GeV}/c^{2}]$',\n",
    "    r'$p$-value$(D^{0})$',\n",
    "    r'$Flight \\; Distance(D^{0})\\;[\\mathrm{cm}]$',\n",
    "    r'$p^{*} (D^{0})\\;[\\mathrm{GeV}/c]$',\n",
    "    r'$\\cos\\theta^*_{daughter_1}$',\n",
    "]\n",
    "\n",
    "ranges = {\n",
    "    'K_kmpip_abs_dr': [0, 0.08],\n",
    "    'pi_kmpip_abs_dr': [0, 0.08],\n",
    "    'K_kmpip_kaonID': [0.5, 1],\n",
    "    'pi_kmpip_pionID': [0.2, 1],\n",
    "    'D0_kmpip_dM': [-0.02, 0.02],\n",
    "    'D0_kmpip_chiProb': [0, 1],\n",
    "    'D0_kmpip_flightDistance': [-0.4, 0.4],\n",
    "    'D0_kmpip_useCMSFrame_p': [2.5, 5.0],\n",
    "    'D0_kmpip_cos_decayAngle_1': [-1, 1],\n",
    "}\n",
    "\n",
    "colors = {\n",
    "    'mc': '#007C91',\n",
    "    'data': 'black',\n",
    "}\n",
    "\n",
    "# === Load Data ===\n",
    "df_mc = DataFrames[\"All_WCh\"]\n",
    "df_data = DataFrames[\"Data_WCh\"]\n",
    "\n",
    "# === Plot Loop ===\n",
    "for var, label in zip(Variables, features):\n",
    "    if var not in ranges:\n",
    "        print(f\"Skipping {var}: no defined range\")\n",
    "        continue\n",
    "\n",
    "    Range = ranges[var]\n",
    "    bin_width = (Range[1] - Range[0]) / bins\n",
    "    edges = np.linspace(Range[0], Range[1], bins + 1)\n",
    "    bin_centers = 0.5 * (edges[:-1] + edges[1:])\n",
    "\n",
    "    # Clean and drop NaN/inf\n",
    "    data_vals = df_data[var].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    mc_vals = df_mc[var].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "    # Histograms\n",
    "    hist_data, _ = np.histogram(data_vals, bins=edges, density=density)\n",
    "    hist_mc_raw, _ = np.histogram(mc_vals, bins=edges, density=density)\n",
    "\n",
    "    # Apply scaling\n",
    "    if density:\n",
    "        hist_mc = hist_mc_raw * scale_factor  # shape only\n",
    "        err_mc = np.sqrt(hist_mc_raw * len(mc_vals)) / len(mc_vals) * scale_factor\n",
    "    else:\n",
    "        hist_mc = hist_mc_raw * scale_factor\n",
    "        err_mc = np.sqrt(hist_mc_raw) * scale_factor\n",
    "\n",
    "    if density:\n",
    "        err_data = np.sqrt(hist_data * len(data_vals)) / len(data_vals)\n",
    "    else:\n",
    "        err_data = np.sqrt(hist_data)\n",
    "\n",
    "    # Ratio and uncertainty\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        ratio = hist_data / hist_mc\n",
    "        ratio[~np.isfinite(ratio)] = 0\n",
    "\n",
    "        err_ratio = ratio * np.sqrt(\n",
    "            (err_data / np.maximum(hist_data, 1e-10))**2 +\n",
    "            (err_mc / np.maximum(hist_mc, 1e-10))**2\n",
    "        )\n",
    "        err_ratio[~np.isfinite(err_ratio)] = 0\n",
    "\n",
    "    # === Plot\n",
    "    fig, (ax1, ax2) = plt.subplots(nrows=2, sharex=True, figsize=figsize,\n",
    "                                   gridspec_kw={\"height_ratios\": [3, 1]})\n",
    "\n",
    "    # Top: Data vs MC\n",
    "    ax1.hist(edges[:-1], bins=edges, weights=hist_mc, histtype='step',\n",
    "             linewidth=2.5, color=colors['mc'], label=\"Generic MC\")\n",
    "\n",
    "    ax1.errorbar(bin_centers, hist_data, yerr=err_data, fmt='o',\n",
    "                 color=colors['data'], label=\"Data\", markersize=3,\n",
    "                 capsize=1, elinewidth=1)\n",
    "\n",
    "    ax1.set_ylabel(r'$Entries/({:.3f})$'.format(bin_width))\n",
    "    ax1.set_title(r\"$\\int\\mathcal{L}dt =\\;364.093$ fb$^{-1}$\", loc=\"right\")\n",
    "    ax1.set_xlim(Range)\n",
    "    ax1.legend(loc='upper right')\n",
    "\n",
    "    # Bottom: Ratio\n",
    "    ax2.axhline(1.0, color='black', lw=1)\n",
    "    ax2.axhline(1.1, color='gray', lw=1, ls='dashed')\n",
    "    ax2.axhline(0.9, color='gray', lw=1, ls='dashed')\n",
    "    ax2.errorbar(bin_centers, ratio, yerr=err_ratio, fmt='o',\n",
    "                 color='black', markersize=3, capsize=1)\n",
    "\n",
    "    ax2.set_ylabel(\"Data / MC\")\n",
    "    ax2.set_xlabel(label)\n",
    "    ax2.set_xlim(Range)\n",
    "    ax2.set_ylim(0.5, 1.5)\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Belle2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
