{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "\n",
    "mem = psutil.virtual_memory()\n",
    "print(f\"Total RAM: {mem.total / 1e9:.2f} GB\")\n",
    "print(f\"Available: {mem.available / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall -y scikit-learn\n",
    "# !pip install scikit-learn==1.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install --upgrade pip\n",
    "# ! pip install --user xgboost seaborn\n",
    "# ! pip install --user bayesian-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mplhep\n",
    "import sys\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import uproot\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.datasets import make_classification,make_regression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import auc,roc_curve,confusion_matrix,classification_report,precision_recall_curve,mean_squared_error,accuracy_score,roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV, cross_validate, validation_curve,train_test_split,KFold,learning_curve,cross_val_score\n",
    "from sklearn.utils import compute_sample_weight\n",
    "from scipy.stats import ks_2samp\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from hep_ml import gradientboosting as ugb\n",
    "from hep_ml.uboost import uBoostClassifier\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from scipy.stats import randint, uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\n",
    "    \"axes.labelsize\": 16,\n",
    "    \"xtick.labelsize\": 12,\n",
    "    \"ytick.labelsize\": 12,\n",
    "    \"legend.fontsize\": 16,\n",
    "    \"figure.titlesize\": 20\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 200000)\n",
    "pd.set_option('display.max_columns', 200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/home/belle2/amubarak/Ds2D0enue_Analysis/07-Python_Functions/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep-Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct Charge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uproot\n",
    "import pandas as pd\n",
    "\n",
    "# === Load only selected branches ===\n",
    "with open(\"/home/belle2/amubarak/Ds2D0enue_Analysis/03-Grid/Save_var.txt\") as f:\n",
    "    variables_to_load = [\n",
    "        line.strip().strip(\",\").strip('\"').strip(\"'\")\n",
    "        for line in f\n",
    "        if line.strip() and not line.strip().startswith(\"#\")\n",
    "    ]\n",
    "\n",
    "# Make sure to include BDT output variable\n",
    "if \"Ds_FakeD0BDT\" not in variables_to_load:\n",
    "    variables_to_load.append(\"Ds_FakeD0BDT\")\n",
    "\n",
    "# === Sample list ===\n",
    "samples = [\"Signal\", \"BB\", \"ccbar\", \"ddbar\", \"ssbar\", \"taupair\", \"uubar\"]\n",
    "GenEvents = samples.copy()\n",
    "\n",
    "# === Input configuration ===\n",
    "Date = \"0530\"\n",
    "Attempt = \"0\"\n",
    "input_dir = \"/group/belle/users/amubarak/03-ML/FakeD0/\"\n",
    "\n",
    "# === Load ROOT files into DataFrames ===\n",
    "DataFrames = {}\n",
    "\n",
    "for s in samples:\n",
    "    if s == \"Signal\":\n",
    "        file_path = os.path.join(input_dir, \"Ds2D0enu-Signal_withBDT.root\")\n",
    "    else:\n",
    "        file_path = os.path.join(\n",
    "            input_dir, f\"Ds2D0e-Generic_Ds_{Date}25_{Attempt}_{s}_withBDT.root\"\n",
    "        )\n",
    "\n",
    "    print(f\"Loading: {file_path}\")\n",
    "    DataFrames[s] = uproot.concatenate(\n",
    "        f\"{file_path}:Dstree\",\n",
    "        filter_name=variables_to_load,\n",
    "        library=\"pd\"\n",
    "    )\n",
    "\n",
    "# === Define combined background ===\n",
    "background_samples = [\"BB\", \"ccbar\", \"ddbar\", \"ssbar\", \"taupair\", \"uubar\"]\n",
    "DataFrames[\"All\"] = pd.concat([DataFrames[s] for s in background_samples], ignore_index=True)\n",
    "\n",
    "# === Combine uds backgrounds for convenience ===\n",
    "DataFrames[\"uds\"] = pd.concat(\n",
    "    [DataFrames[\"uubar\"], DataFrames[\"ddbar\"], DataFrames[\"ssbar\"]],\n",
    "    ignore_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrong Charge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uproot\n",
    "import pandas as pd\n",
    "\n",
    "# === Load only selected branches ===\n",
    "with open(\"/home/belle2/amubarak/Ds2D0enue_Analysis/03-Grid/Save_var.txt\") as f:\n",
    "    variables_to_load = [\n",
    "        line.strip().strip(\",\").strip('\"').strip(\"'\")\n",
    "        for line in f\n",
    "        if line.strip() and not line.strip().startswith(\"#\")\n",
    "    ]\n",
    "\n",
    "# Ensure BDT variable is included\n",
    "if \"Ds_FakeD0BDT\" not in variables_to_load:\n",
    "    variables_to_load.append(\"Ds_FakeD0BDT\")\n",
    "\n",
    "# === Wrong-charge samples ===\n",
    "samples_WCh = [\"Signal_WCh\", \"BB_WCh\", \"ccbar_WCh\", \"ddbar_WCh\", \"ssbar_WCh\", \"taupair_WCh\", \"uubar_WCh\", \"Data_WCh\"]\n",
    "background_WCh = [\"BB_WCh\", \"ccbar_WCh\", \"ddbar_WCh\", \"ssbar_WCh\", \"taupair_WCh\", \"uubar_WCh\"]\n",
    "\n",
    "Date_WCh = \"0630\"\n",
    "Attempt_WCh = \"0\"\n",
    "input_dir_WCh = \"/group/belle/users/amubarak/03-ML/FakeD0_WCh/\"\n",
    "\n",
    "# === Load wrong-charge ROOT files into DataFrames ===\n",
    "DataFrames = {} if \"DataFrames\" not in globals() else DataFrames\n",
    "\n",
    "for s in samples_WCh:\n",
    "    if s == \"Signal_WCh\":\n",
    "        file_path = os.path.join(input_dir_WCh, \"Ds2D0enu-Signal_WCh_withBDT.root\")\n",
    "    else:\n",
    "        tag = s.replace(\"_WCh\", \"\")\n",
    "        file_path = os.path.join(\n",
    "            input_dir_WCh,\n",
    "            f\"Ds2D0e-Generic_Ds_{Date_WCh}25_{Attempt_WCh}_{tag}_withBDT.root\"\n",
    "        )\n",
    "\n",
    "    print(f\"Loading: {file_path}\")\n",
    "    DataFrames[s] = uproot.concatenate(\n",
    "        f\"{file_path}:Dstree\",\n",
    "        filter_name=variables_to_load,\n",
    "        library=\"pd\"\n",
    "    )\n",
    "\n",
    "# === Combine wrong-charge backgrounds ===\n",
    "DataFrames[\"All_WCh\"] = pd.concat([DataFrames[s] for s in background_WCh], ignore_index=True)\n",
    "DataFrames[\"uds_WCh\"] = pd.concat(\n",
    "    [DataFrames[s] for s in [\"uubar_WCh\", \"ddbar_WCh\", \"ssbar_WCh\"]],\n",
    "    ignore_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reverse PID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uproot\n",
    "import pandas as pd\n",
    "\n",
    "# === Load only selected branches ===\n",
    "with open(\"/home/belle2/amubarak/Ds2D0enue_Analysis/03-Grid/Save_var.txt\") as f:\n",
    "    variables_to_load = [\n",
    "        line.strip().strip(\",\").strip('\"').strip(\"'\")\n",
    "        for line in f\n",
    "        if line.strip() and not line.strip().startswith(\"#\")\n",
    "    ]\n",
    "\n",
    "# Ensure BDT variable is included\n",
    "if \"Ds_FakeD0BDT\" not in variables_to_load:\n",
    "    variables_to_load.append(\"Ds_FakeD0BDT\")\n",
    "\n",
    "# === Wrong-charge samples ===\n",
    "samples_ReverseID = [\"Signal_ReverseID\", \"BB_ReverseID\", \"ccbar_ReverseID\", \"ddbar_ReverseID\", \"ssbar_ReverseID\", \"taupair_ReverseID\", \"uubar_ReverseID\", \"Data_ReverseID\"]\n",
    "background_ReverseID = [\"BB_ReverseID\", \"ccbar_ReverseID\", \"ddbar_ReverseID\", \"ssbar_ReverseID\", \"taupair_ReverseID\", \"uubar_ReverseID\"]\n",
    "\n",
    "Date_ReverseID = \"0626\"\n",
    "Attempt_ReverseID = \"0\"\n",
    "input_dir_ReverseID = \"/group/belle/users/amubarak/03-ML/FakeD0_ReverseID/\"\n",
    "\n",
    "# === Load wrong-charge ROOT files into DataFrames ===\n",
    "DataFrames = {} if \"DataFrames\" not in globals() else DataFrames\n",
    "\n",
    "for s in samples_ReverseID:\n",
    "    if s == \"Signal_ReverseID\":\n",
    "        file_path = os.path.join(input_dir_ReverseID, \"Ds2D0enu-Signal_ReverseID_withBDT.root\")\n",
    "    else:\n",
    "        tag = s.replace(\"_ReverseID\", \"\")\n",
    "        file_path = os.path.join(\n",
    "            input_dir_ReverseID,\n",
    "            f\"Ds2D0e-Generic_Ds_{Date_ReverseID}25_{Attempt_ReverseID}_{tag}_withBDT.root\"\n",
    "        )\n",
    "\n",
    "    print(f\"Loading: {file_path}\")\n",
    "    DataFrames[s] = uproot.concatenate(\n",
    "        f\"{file_path}:Dstree\",\n",
    "        filter_name=variables_to_load,\n",
    "        library=\"pd\"\n",
    "    )\n",
    "\n",
    "# === Combine wrong-charge backgrounds ===\n",
    "DataFrames[\"All_ReverseID\"] = pd.concat([DataFrames[s] for s in background_ReverseID], ignore_index=True)\n",
    "DataFrames[\"uds_ReverseID\"] = pd.concat(\n",
    "    [DataFrames[s] for s in [\"uubar_ReverseID\", \"ddbar_ReverseID\", \"ssbar_ReverseID\"]],\n",
    "    ignore_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reverse PID and Wrong Charge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import uproot\n",
    "# import pandas as pd\n",
    "\n",
    "# # === Load only selected branches ===\n",
    "# with open(\"/home/belle2/amubarak/Ds2D0enue_Analysis/03-Grid/Save_var.txt\") as f:\n",
    "#     variables_to_load = [\n",
    "#         line.strip().strip(\",\").strip('\"').strip(\"'\")\n",
    "#         for line in f\n",
    "#         if line.strip() and not line.strip().startswith(\"#\")\n",
    "#     ]\n",
    "\n",
    "# # Ensure BDT variable is included\n",
    "# if \"Ds_FakeD0BDT\" not in variables_to_load:\n",
    "#     variables_to_load.append(\"Ds_FakeD0BDT\")\n",
    "\n",
    "# # === Wrong-charge samples ===\n",
    "# samples_ReverseID_WCh = [\"BB_ReverseID_WCh\", \"ccbar_ReverseID_WCh\", \"ddbar_ReverseID_WCh\", \"ssbar_ReverseID_WCh\", \"taupair_ReverseID_WCh\", \"uubar_ReverseID_WCh\", \"Data_ReverseID_WCh\"]\n",
    "# background_ReverseID_WCh = [\"BB_ReverseID_WCh\", \"ccbar_ReverseID_WCh\", \"ddbar_ReverseID_WCh\", \"ssbar_ReverseID_WCh\", \"taupair_ReverseID_WCh\", \"uubar_ReverseID_WCh\"]\n",
    "\n",
    "# Date_ReverseID_WCh = \"0708\"\n",
    "# Attempt_ReverseID_WCh = \"0\"\n",
    "# input_dir_ReverseID_WCh = \"/group/belle/users/amubarak/03-ML/FakeD0_ReverseID_WCh/\"\n",
    "\n",
    "# # === Load wrong-charge ROOT files into DataFrames ===\n",
    "# DataFrames = {} if \"DataFrames\" not in globals() else DataFrames\n",
    "\n",
    "# for s in samples_ReverseID_WCh:\n",
    "#     if s == \"Signal_ReverseID_WCh\":\n",
    "#         file_path = os.path.join(input_dir_ReverseID_WCh, \"Ds2D0enu-Signal_ReverseID_WCh_withBDT.root\")\n",
    "#     else:\n",
    "#         tag = s.replace(\"_ReverseID_WCh\", \"\")\n",
    "#         file_path = os.path.join(\n",
    "#             input_dir_ReverseID_WCh,\n",
    "#             f\"Ds2D0e-Generic_Ds_{Date_ReverseID_WCh}25_{Attempt_ReverseID_WCh}_{tag}_withBDT.root\"\n",
    "#         )\n",
    "\n",
    "#     print(f\"Loading: {file_path}\")\n",
    "#     DataFrames[s] = uproot.concatenate(\n",
    "#         f\"{file_path}:Dstree\",\n",
    "#         filter_name=variables_to_load,\n",
    "#         library=\"pd\"\n",
    "#     )\n",
    "\n",
    "# # === Combine wrong-charge backgrounds ===\n",
    "# DataFrames[\"All_ReverseID_WCh\"] = pd.concat([DataFrames[s] for s in background_ReverseID_WCh], ignore_index=True)\n",
    "# DataFrames[\"uds_ReverseID_WCh\"] = pd.concat(\n",
    "#     [DataFrames[s] for s in [\"uubar_ReverseID_WCh\", \"ddbar_ReverseID_WCh\", \"ssbar_ReverseID_WCh\"]],\n",
    "#     ignore_index=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The line below is to look at the available variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(DataFrames.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrames['Signal'].columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "The code below will be used to apply cuts to the data.  \n",
    "The range of the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Electron ID\n",
    "#-------------------\n",
    "# DataFrames[\"Signal\"] = DataFrames[\"Signal\"][DataFrames[\"Signal\"]['e_electronID']>=0.95]\n",
    "# DataFrames[\"ccbar\"] = DataFrames[\"ccbar\"][DataFrames[\"ccbar\"]['e_electronID']>=0.95]\n",
    "# DataFrames[\"Signal\"] = DataFrames[\"Signal\"][DataFrames[\"Signal\"]['Ds_gammaveto_em_electronID']>=0.95]\n",
    "# DataFrames[\"ccbar\"] = DataFrames[\"ccbar\"][DataFrames[\"ccbar\"]['Ds_gammaveto_em_electronID']>=0.95]\n",
    "\n",
    "# Photon Conversion\n",
    "#-------------------\n",
    "# DataFrames[samples[0]] = DataFrames[samples[0]][DataFrames[samples[0]]['Ds_gammaveto_M_Correction']>=0.1]\n",
    "# DataFrames[samples[1]] = DataFrames[samples[1]][DataFrames[samples[1]]['Ds_gammaveto_M_Correction']>=0.1]\n",
    "\n",
    "# Peaking Background Removal\n",
    "#----------------------------\n",
    "# DataFrames[\"ccbar\"] = DataFrames[\"ccbar\"][(DataFrames[\"ccbar\"]['Ds_diff_D0pi']>=0.15)]\n",
    "# DataFrames[\"Signal\"] = DataFrames[\"Signal\"][(DataFrames[\"Signal\"]['Ds_diff_D0pi']>=0.15)]\n",
    "\n",
    "# # Vertex Fitting\n",
    "# #----------------\n",
    "# DataFrames[\"Signal\"] = DataFrames[\"Signal\"][DataFrames[\"Signal\"]['Ds_chiProb']>=0.01]\n",
    "# DataFrames[\"ccbar\"] = DataFrames[\"ccbar\"][DataFrames[\"ccbar\"]['Ds_chiProb']>=0.01]\n",
    "\n",
    "# Dalitz Removal\n",
    "#----------------------------\n",
    "# DataFrames[\"ccbar\"] = DataFrames[\"ccbar\"][(DataFrames[\"ccbar\"]['Ds_pi0veto_M_Correction']<=0.08) | (DataFrames[\"ccbar\"]['Ds_pi0veto_M_Correction']>=0.16)]\n",
    "# DataFrames[\"Signal\"] = DataFrames[\"Signal\"][(DataFrames[\"Signal\"]['Ds_pi0veto_M_Correction']<=0.08) | (DataFrames[\"Signal\"]['Ds_pi0veto_M_Correction']>=0.16)]\n",
    "\n",
    "# Vertex Fit\n",
    "#----------------\n",
    "# DataFrames[samples[0]] = DataFrames[samples[0]][DataFrames[samples[0]]['Ds_chiProb_rank']==1]\n",
    "# DataFrames[samples[1]] = DataFrames[samples[1]][DataFrames[samples[1]]['Ds_chiProb_rank']==1]\n",
    "\n",
    "# D0 Invariant Mass\n",
    "#-----------------------\n",
    "# DataFrames[samples[0]] = DataFrames[samples[0]][(DataFrames[samples[0]]['Ds_D0_sideband']==1)]\n",
    "# DataFrames[samples[1]] = DataFrames[samples[1]][(DataFrames[samples[1]]['Ds_D0_sideband']==1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $D^{*+}$ Suppression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(abs(DataFrames[\"All_ReverseID\"][(DataFrames[\"All_ReverseID\"][\"e_electronID\"] < 0.5)])[['e_mcPDG']].value_counts(normalize=True,dropna=False).apply(lambda x: f\"{x:.6f}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut_low = 0.14543 - (2 * 0.00041121)\n",
    "# cut_high = 0.14543 + (2 * 0.00041121)\n",
    "\n",
    "# for key in DataFrames.keys():\n",
    "#     df = DataFrames[key]\n",
    "#     if \"Ds_diff_D0pi\" in df.columns:\n",
    "#         DataFrames[key] = df[\n",
    "#             (df[\"Ds_diff_D0pi\"] <= cut_low) | (df[\"Ds_diff_D0pi\"] >= cut_high)\n",
    "#         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrames[\"All\"][\"D0_isSignal\"] = DataFrames[\"All\"][\"D0_isSignal\"].replace(np.nan, 0)\n",
    "\n",
    "for s in GenEvents[0:]: # loop over samples\n",
    "    DataFrames[s][\"D0_isSignal\"] = DataFrames[s][\"D0_isSignal\"].replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrames[\"All\"][\"Ds_isSignal\"] = DataFrames[\"All\"][\"Ds_isSignal\"].replace(np.nan, 0)\n",
    "\n",
    "for s in GenEvents[0:]: # loop over samples\n",
    "    DataFrames[s][\"Ds_isSignal\"] = DataFrames[s][\"Ds_isSignal\"].replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fake $D^0$ BDT Cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrames[\"All\"] = DataFrames[\"All\"][(DataFrames[\"All\"][\"Ds_FakeD0BDT\"]>=0.556)]\n",
    "\n",
    "# for s in GenEvents[0:]: # loop over samples\n",
    "#     DataFrames[s] = DataFrames[s][(DataFrames[s][\"Ds_FakeD0BDT\"]>=0.556)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background Suppression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrames[samples[0]].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Signal Number: \",len(DataFrames[\"Signal\"]))\n",
    "print(\"Background Number: \",len(DataFrames[\"All\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('default')\n",
    "plt.rcParams.update({\n",
    "    \"axes.labelsize\": 16,\n",
    "    \"xtick.labelsize\": 12,\n",
    "    \"ytick.labelsize\": 12,\n",
    "    \"legend.fontsize\": 14,\n",
    "    \"figure.titlesize\": 18\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Input Variables and Labels ===\n",
    "Variables = [\n",
    "    \"Ds_FakeD0BDT\",\n",
    "    \"Ds_chiProb\",\n",
    "    \"Ds_gammaveto_M_Correction\",\n",
    "    \"Ds_Ds_starminusDs_M_Correction\"\n",
    "]\n",
    "\n",
    "features = [\n",
    "    r'$Fake\\;D^{0}\\;Suppression$',\n",
    "    r'$p$-value$_{IP}(D_{s}^{+})$',\n",
    "    r'$m(e_{\\mathrm{sig}}^{+}e_{\\mathrm{ROE}}^{-})\\;[\\mathrm{GeV}/c^2]$',\n",
    "    r'$\\Delta m(D_{s}^{*+} - D_{s}^{+})\\;[\\mathrm{GeV}/c^2]$'\n",
    "]\n",
    "\n",
    "# === Plot Ranges ===\n",
    "ranges = {\n",
    "    \"Ds_FakeD0BDT\": [0.0, 1.0],\n",
    "    \"Ds_chiProb\": [0.0, 1.0],\n",
    "    \"Ds_gammaveto_M_Correction\": [0.0, 0.2],\n",
    "    \"Ds_Ds_starminusDs_M_Correction\": [0.0, 0.2]\n",
    "}\n",
    "\n",
    "bins = 50\n",
    "density = True\n",
    "\n",
    "# === Colors and Labels ===\n",
    "colors = {\n",
    "    \"signal\": \"#1f77b4\",     # Blue\n",
    "    \"background\": \"#d62728\"  # Red\n",
    "}\n",
    "labels = {\n",
    "    \"signal\": r'$Signal$',\n",
    "    \"background\": r'$Background$'\n",
    "}\n",
    "\n",
    "# === Extract real signal and background ===\n",
    "df_true_signal = DataFrames[\"Signal\"][DataFrames[\"Signal\"][\"Ds_isSignal\"] == 1]\n",
    "df_background = DataFrames[\"All\"]\n",
    "\n",
    "# === Plotting ===\n",
    "for var, label in zip(Variables, features):\n",
    "    if var not in ranges:\n",
    "        print(f\"Skipping {var}: no range defined.\")\n",
    "        continue\n",
    "\n",
    "    var_range = ranges[var]\n",
    "    bin_width = (var_range[1] - var_range[0]) / bins\n",
    "\n",
    "    signal_data = df_true_signal[var].dropna()\n",
    "    background_data = df_background[var].dropna()\n",
    "\n",
    "    plt.hist(signal_data, label=labels[\"signal\"],\n",
    "             histtype='step', density=density,\n",
    "             bins=bins, range=var_range, linewidth=2, color=colors[\"signal\"])\n",
    "\n",
    "    plt.hist(background_data, label=labels[\"background\"],\n",
    "             histtype='step', density=density,\n",
    "             bins=bins, range=var_range, linewidth=2, color=colors[\"background\"])\n",
    "\n",
    "    plt.xlabel(label)\n",
    "    plt.ylabel(r'$Norm.\\;Entries/({:.3f})$'.format(bin_width))\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Variables = [\n",
    "    # \"Ds_Ds_starminusDs_M_Correction\",\n",
    "    \"Ds_FakeD0BDT\",\n",
    "    \"Ds_chiProb\",\n",
    "    # \"D0_cos_theta\",\n",
    "    \"e_dr\",\"e_dz\",\n",
    "    \"e_cos_theta\",\n",
    "    \"e_pt\",\n",
    "    \"e_p\"\n",
    "]\n",
    "\n",
    "features = [\n",
    "    # r'$\\Delta m(D_{s}^{*+} - D_{s}^{+})$',\n",
    "    r'$Fake\\;D^{0}\\;Suppression$',\n",
    "    r'$p-value_{IP}(D_{s}^{+})$',\n",
    "    # r'$m(e_{\\mathrm{sig}}^{+}e_{\\mathrm{ROE}}^{-})$',\n",
    "    # r'$\\Delta m(D_{s}^{*+} - D_{s}^{+})$',\n",
    "    # \"D0_cos_theta\",\n",
    "    r'$d_{r}(e)$', r'$d_{z}(e)$', \n",
    "    r'$\\cos\\theta(e)$',\n",
    "    r'$p_{t}(e)$',\n",
    "    r'$p(e)$'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 15))\n",
    "\n",
    "heatmap = sns.heatmap(DataFrames[\"Signal\"][Variables].corr(), annot=True, cmap=\"coolwarm\",vmin=-1, vmax=1)\n",
    "\n",
    "heatmap.set_title('Signal Correlation Heatmap', fontdict={'fontsize':20}, pad=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 15))\n",
    "\n",
    "heatmap = sns.heatmap(DataFrames[\"All\"][Variables].corr(), annot=True, cmap=\"coolwarm\",vmin=-1, vmax=1)\n",
    "\n",
    "heatmap.set_title('Background Correlation Heatmap', fontdict={'fontsize':20}, pad=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  Organise data ready for the machine learning model\n",
    "\n",
    "# # for sklearn data are usually organised\n",
    "# # into one 2D array of shape (n_samples x n_features)\n",
    "# # containing all the data and one array of categories\n",
    "# # of length n_samples\n",
    "\n",
    "# all_MC = []  # define empty list that will contain all features for the MC\n",
    "# for s in GenEvents:  # loop over the different samples\n",
    "#     if s != \"data\":  # only MC should pass this\n",
    "#         all_MC.append(\n",
    "#             DataFrames[s][Variables]\n",
    "#         )  # append the MC dataframe to the list containing all MC features\n",
    "# X = np.concatenate(\n",
    "#     all_MC\n",
    "# )  # concatenate the list of MC dataframes into a single 2D array of features, called X\n",
    "\n",
    "# all_y = (\n",
    "#     []\n",
    "# )  # define empty list that will contain labels whether an event in signal or background\n",
    "# for s in GenEvents:  # loop over the different samples\n",
    "#     if s != \"data\":  # only MC should pass this\n",
    "#         if \"Signal\" in s:  # only signal MC should pass this\n",
    "#             all_y.append(\n",
    "#                 np.ones(DataFrames[s].shape[0], dtype=np.int32)\n",
    "#             )  # signal events are labelled with 1\n",
    "#         else:  # only background MC should pass this\n",
    "#             all_y.append(\n",
    "#                 np.zeros(DataFrames[s].shape[0], dtype=np.int32)\n",
    "#             )  # background events are labelled 0\n",
    "# y = np.concatenate(\n",
    "#     all_y\n",
    "# )  # concatenate the list of labels into a single 1D array of labels, called y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load Data ===\n",
    "all_MC = []\n",
    "all_y = []\n",
    "\n",
    "fitvar = \"Ds_massDifference_0\"\n",
    "Variables_with_fitvar = Variables + [fitvar]\n",
    "\n",
    "for s in GenEvents:\n",
    "    if s == \"data\":\n",
    "        continue\n",
    "    df = DataFrames[s]\n",
    "    if \"Signal\" in s:\n",
    "        df = df[df[\"Ds_isSignal\"] == 1]\n",
    "        all_y.append(np.ones(len(df), dtype=np.int32))\n",
    "    else:\n",
    "        all_y.append(np.zeros(len(df), dtype=np.int32))\n",
    "    all_MC.append(df[Variables_with_fitvar])\n",
    "\n",
    "# Use pd.concat, not np.concatenate\n",
    "X = pd.concat(all_MC)\n",
    "y = np.concatenate(all_y)\n",
    "\n",
    "# === Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === uBoost Setup\n",
    "weights = compute_sample_weight('balanced', y_train)\n",
    "\n",
    "uboost = uBoostClassifier(\n",
    "    uniform_features=[fitvar],\n",
    "    uniform_label=1,\n",
    "    train_features=Variables,\n",
    "    n_estimators=100,\n",
    "    efficiency_steps=12,\n",
    "    n_threads=4,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "uboost.fit(X_train, y_train, sample_weight=weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This optimization is pulling too much resources and ending the connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hep_ml.uboost import uBoostClassifier\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "fitvar = \"Ds_massDifference_0\"  # decorrelation target\n",
    "uniform_variables = Z_train.reshape(-1, 1)  # Z_train comes from your earlier train_test_split\n",
    "\n",
    "# Define the parameter space\n",
    "param_dist = {\n",
    "    \"max_depth\": randint(1, 5),\n",
    "    \"n_estimators\": randint(100, 201),\n",
    "    \"efficiency_steps\": randint(6, 16)  # typical range for uBoost\n",
    "}\n",
    "\n",
    "# Sample 50 combinations\n",
    "param_list = list(ParameterSampler(param_dist, n_iter=50, random_state=42))\n",
    "\n",
    "best_model = None\n",
    "best_score = -np.inf\n",
    "best_params = None\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "for params in tqdm(param_list):\n",
    "    model = uBoostClassifier(\n",
    "        uniform_features=[fitvar],\n",
    "        uniform_label=1,\n",
    "        train_features=Variables,\n",
    "        base_estimator=DecisionTreeClassifier(max_depth=params[\"max_depth\"]),\n",
    "        n_estimators=params[\"n_estimators\"],\n",
    "        efficiency_steps=params[\"efficiency_steps\"],\n",
    "        n_threads=4,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        model.fit(X_train, y_train, sample_weight=weights)\n",
    "        y_pred = model.predict_proba(X_test)[:, 1]\n",
    "        score = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            uboost_final = model\n",
    "            best_params = params\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed for params: {params} — {e}\")\n",
    "\n",
    "# === Results ===\n",
    "print(\"\\nBest parameters found:\")\n",
    "for k, v in best_params.items():\n",
    "    print(f\"{k:20s}: {v}\")\n",
    "print(f\"Best ROC AUC Score: {best_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uboost_final = uboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Compute permutation importance\n",
    "result = permutation_importance(uboost_final, X_test, y_test, n_repeats=10, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Convert to DataFrame\n",
    "feature_imp = pd.DataFrame({'Value': result.importances_mean, 'Feature': features})\n",
    "feature_imp = feature_imp.sort_values(by=\"Value\", ascending=False)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(16, 8))\n",
    "sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp)\n",
    "plt.title('Permutation Importance (uBoost)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "def get_pulls(counts,errors,pdf):\n",
    "    pull = (-pdf + counts) / errors\n",
    "    return pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_train_test(clf, X_train, y_train, X_test, y_test):\n",
    "    decisions = [] # list to hold decisions of classifier\n",
    "    for X,y in ((X_train, y_train), (X_test, y_test)): # train and test\n",
    "        if hasattr(clf, \"predict_proba\"): # if predict_proba function exists\n",
    "            d1 = clf.predict_proba(X[y<0.5])[:, 1] # background\n",
    "            d2 = clf.predict_proba(X[y>0.5])[:, 1] # signal\n",
    "        else: # predict_proba function doesn't exist\n",
    "            X_tensor = torch.as_tensor(X, dtype=torch.float) # make tensor from X_test_scaled\n",
    "            y_tensor = torch.as_tensor(y, dtype=torch.long) # make tensor from y_test\n",
    "            X_var, y_var = Variable(X_tensor), Variable(y_tensor) # make variables from tensors\n",
    "            d1 = clf(X_var[y_var<0.5])[1][:, 1].cpu().detach().numpy() # background\n",
    "            d2 = clf(X_var[y_var>0.5])[1][:, 1].cpu().detach().numpy() # signal\n",
    "        decisions += [d1, d2] # add to list of classifier decision\n",
    "\n",
    "    #pd.set_option('max_columns', None)\n",
    "#     %config InlineBackend.figure_format = 'retina'\n",
    "    # plt.style.use('belle2')\n",
    "    lw=3\n",
    "\n",
    "    fig,axs=plt.subplots(3,1,figsize=(10,10),gridspec_kw={'height_ratios':[1,0.2,0.2]})\n",
    "\n",
    "    bins = 50\n",
    "    bin_edges = np.linspace(0,1,bins)\n",
    "    \n",
    "    test_bkg_count_weight=bins/len(decisions[2])\n",
    "    test_sig_count_weight=bins/len(decisions[3])\n",
    "    test_bkg_counts,test_bkg_bins = np.histogram(decisions[2],bins=bins,range=(0,1))\n",
    "    test_sig_counts,test_sig_bins = np.histogram(decisions[3],bins=bins,range=(0,1))\n",
    "\n",
    "    train_bkg_counts,train_bkg_bins,_etc=axs[0].hist(decisions[0],color = 'tab:blue',\n",
    "            histtype='step',bins=bins,density=True,range=(0,1),linewidth=lw,label='Train Background')\n",
    "    train_sig_counts,train_sig_bins,_etc=axs[0].hist(decisions[1],color = 'tab:red',\n",
    "            histtype='step',bins=bins,density=True,range=(0,1),linewidth=lw,label=r'Train Signal')\n",
    "    axs[0].hist(decisions[0],color = 'tab:blue',\n",
    "            histtype='stepfilled',alpha=0.4,bins=bins,density=True,range=(0,1))\n",
    "    axs[0].hist(decisions[1],color = 'tab:red',\n",
    "            histtype='stepfilled',alpha=0.4,bins=bins,density=True,range=(0,1))\n",
    "    bin_width=test_bkg_bins[1]-test_bkg_bins[0]\n",
    "    bin_centers=[el+(bin_width/2) for el in test_bkg_bins[:-1]]\n",
    "\n",
    "    axs[0].errorbar(bin_centers,test_bkg_count_weight*test_bkg_counts,\n",
    "                yerr=test_bkg_count_weight*np.sqrt(test_bkg_counts),label='Test Background',color='tab:blue',\n",
    "                marker='o',linewidth=lw,ls='')\n",
    "    axs[0].errorbar(bin_centers,test_sig_count_weight*test_sig_counts,\n",
    "                yerr=test_sig_count_weight*np.sqrt(test_sig_counts),label='Test Signal',color='tab:red',\n",
    "                marker='o',linewidth=lw,ls='')\n",
    "    axs[0].set_title(r'$D_{s}^{+} \\rightarrow D^{0} e^{+} \\nu_{e}$',loc='left')\n",
    "    axs[0].set_xlim(0,1)\n",
    "    axs[0].set_ylim(0)\n",
    "    axs[0].set_ylabel('Event Density')\n",
    "\n",
    "    x= decisions[1]\n",
    "    y=  decisions[3]\n",
    "    ks_p_value_sig = ks_2samp(x, y)[1]\n",
    "\n",
    "    x= decisions[0]\n",
    "    y= decisions[2]\n",
    "    ks_p_value_bkg = ks_2samp(x, y)[1]\n",
    "\n",
    "    leg=axs[0].legend(loc='upper center',title=f\"Sig K-S test score: {ks_p_value_sig:0.3f}\"+\n",
    "                      \"\\n\"+f\"Bkg K-S test score: {ks_p_value_bkg:0.3f}\")\n",
    "    leg._legend_box.align = \"left\"  \n",
    "\n",
    "    pulls=get_pulls(test_bkg_count_weight*test_bkg_counts,test_bkg_count_weight*np.sqrt(test_bkg_counts),np.array(train_bkg_counts))\n",
    "    axs[1].bar(bin_centers,pulls,width=bin_width)\n",
    "    axs[1].set_xlim(0,1)\n",
    "    axs[1].set_ylabel('Pulls')\n",
    "    axs[1].set_ylim(-5,5)\n",
    "\n",
    "    pulls=get_pulls(test_sig_count_weight*test_sig_counts,test_sig_count_weight*np.sqrt(test_sig_counts),np.array(train_sig_counts))\n",
    "    axs[2].bar(bin_centers,pulls,width=bin_width,color='tab:red')\n",
    "    axs[2].set_xlim(0,1)\n",
    "    axs[2].set_ylabel('Pulls')\n",
    "    axs[2].set_ylim(-5,5)\n",
    "    axs[2].set_xlabel(r'BDT output')\n",
    "\n",
    "    return decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decisions = compare_train_test(uboost_final, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basf2 ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # compute ROC \n",
    "# sig_train=decisions[1]\n",
    "# sig_test=decisions[3]\n",
    "# bkg_train=decisions[0]\n",
    "# bkg_test=decisions[2]\n",
    "\n",
    "# bdt_cuts=np.linspace(0,1,100)\n",
    "# sig_efficiency_train=[]\n",
    "# bkg_rejection_train=[]\n",
    "# den_sig_train=len(sig_train)\n",
    "# den_bkg_train=len(bkg_train)\n",
    "\n",
    "# sig_efficiency_test=[]\n",
    "# bkg_rejection_test=[]\n",
    "# den_sig_test=len(sig_test)\n",
    "# den_bkg_test=len(bkg_test)\n",
    "\n",
    "\n",
    "# for cut in bdt_cuts:\n",
    "#     num_sig_train=len([el for el in sig_train if el>cut])\n",
    "#     num_bkg_train=len([el for el in bkg_train if el>cut])\n",
    "#     num_sig_test=len([el for el in sig_test if el>cut])\n",
    "#     num_bkg_test=len([el for el in bkg_test if el>cut])\n",
    "    \n",
    "#     sig_efficiency_test.append(num_sig_test/den_sig_test)\n",
    "#     bkg_rejection_test.append(1-(num_bkg_test/den_bkg_test))\n",
    "#     sig_efficiency_train.append(num_sig_train/den_sig_train)\n",
    "#     bkg_rejection_train.append(1-(num_bkg_train/den_bkg_train))\n",
    "\n",
    "# fig,axs=plt.subplots(1,1,figsize=(8,6))\n",
    "# lw=2\n",
    "# axs.plot([1, 0], [0, 1], color='grey', linestyle='--')\n",
    "# axs.plot(bkg_rejection_train,sig_efficiency_train,color='tab:blue',marker='',linewidth=lw,label='Train')\n",
    "# axs.plot(bkg_rejection_test,sig_efficiency_test,color='tab:red',marker='',linewidth=lw,ls='--',label='Test')\n",
    "# axs.set_title(r'$D_{s}^{+} \\rightarrow D^{0} e^{+} \\nu_{e}$',loc='left')\n",
    "\n",
    "# axs.set_ylim(0,1.05)\n",
    "# axs.set_xlim(0,1.05)\n",
    "# axs.legend(loc='lower left')\n",
    "# axs.set_xlabel('Background rejection')\n",
    "# axs.set_ylabel('Signal efficiency')\n",
    "# plt.tight_layout()\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score_test = xgbm_final.predict_proba(X_test)[:, 1]\n",
    "fpr_test, tpr_test, thresholds_test = roc_curve(y_test, y_score_test)\n",
    "area_test = auc(fpr_test, tpr_test)\n",
    "\n",
    "y_score_train = xgbm_final.predict_proba(X_train)[:, 1]\n",
    "fpr_train, tpr_train, thresholds_train = roc_curve(y_train, y_score_train)\n",
    "area_train = auc(fpr_train, tpr_train)\n",
    "\n",
    "# Get classifier scores (probabilities for class 1)\n",
    "train_scores = xgbm_final.predict_proba(X_train)[:, 1]\n",
    "test_scores  = xgbm_final.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Use y_train and y_test to separate signal/background\n",
    "sig_train = train_scores[y_train == 1]\n",
    "bkg_train = train_scores[y_train == 0]\n",
    "sig_test  = test_scores[y_test == 1]\n",
    "bkg_test  = test_scores[y_test == 0]\n",
    "\n",
    "# Optionally, group them into one list like this:\n",
    "decisions = [bkg_train, sig_train, bkg_test, sig_test]\n",
    "\n",
    "bdt_cuts = np.linspace(0, 1, 100)\n",
    "\n",
    "sig_eff_train = []\n",
    "bkg_rej_train = []\n",
    "sig_eff_test = []\n",
    "bkg_rej_test = []\n",
    "fom_vals = []\n",
    "\n",
    "for cut in bdt_cuts:\n",
    "    num_sig_train = np.sum(sig_train > cut)\n",
    "    num_bkg_train = np.sum(bkg_train > cut)\n",
    "    num_sig_test = np.sum(sig_test > cut)\n",
    "    num_bkg_test = np.sum(bkg_test > cut)\n",
    "\n",
    "    # FoM calculation\n",
    "    fom = num_sig_test / np.sqrt(num_sig_test + num_bkg_test) if (num_sig_test + num_bkg_test) > 0 else 0\n",
    "    fom_vals.append(fom)\n",
    "\n",
    "    sig_eff_train.append(num_sig_train / len(sig_train))\n",
    "    bkg_rej_train.append(1 - (num_bkg_train / len(bkg_train)))\n",
    "    sig_eff_test.append(num_sig_test / len(sig_test))\n",
    "    bkg_rej_test.append(1 - (num_bkg_test / len(bkg_test)))\n",
    "\n",
    "# Find optimal FoM point\n",
    "fom_vals = np.array(fom_vals)\n",
    "best_idx = np.argmax(fom_vals)\n",
    "best_cut = bdt_cuts[best_idx]\n",
    "\n",
    "# Plot\n",
    "fig, axs = plt.subplots(1, 1, figsize=(7, 6))\n",
    "lw = 2\n",
    "\n",
    "# axs.plot([0, 1], [0, 1], color='grey', linestyle='--', label='Random')\n",
    "axs.plot(bkg_rej_train, sig_eff_train, color='tab:blue', linewidth=lw, label=f'Train (AUC = {area_train:.2f})')\n",
    "axs.plot(bkg_rej_test, sig_eff_test, color='tab:red', linestyle='--', linewidth=lw, label=f'Test (AUC = {area_test:.2f})')\n",
    "\n",
    "# ① Shade the overfit gap\n",
    "axs.fill_between(bkg_rej_test,\n",
    "                 sig_eff_train,\n",
    "                 sig_eff_test,\n",
    "                 where=(np.array(sig_eff_train) > np.array(sig_eff_test)),\n",
    "                 color='gray', alpha=0.2, label='Overfit Gap')\n",
    "\n",
    "# ② Mark the optimal cut point (from test curve)\n",
    "axs.axhline(sig_eff_test[best_idx], color='black', ls='--', linewidth=1.6,\n",
    "            label=f'Best FoM Cut = {best_cut:.3f}')\n",
    "axs.axvline(bkg_rej_test[best_idx], color='black', ls='--', linewidth=1.6)\n",
    "axs.scatter(bkg_rej_test[best_idx], sig_eff_test[best_idx], color='green', s=50)\n",
    "\n",
    "# Axis labels and formatting\n",
    "axs.set_title(r'$D_{s}^{+} \\rightarrow D^{0} e^{+} \\nu_{e}$', loc='left')\n",
    "axs.set_ylim(0, 1.05)\n",
    "axs.set_xlim(0, 1.05)\n",
    "axs.set_xlabel('Background rejection')\n",
    "axs.set_ylabel('Signal efficiency')\n",
    "axs.legend(loc='lower left')\n",
    "axs.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learing ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score_test = xgbm_final.predict_proba(X_test)[:, 1]\n",
    "fpr_test, tpr_test, thresholds_test = roc_curve(y_test, y_score_test)\n",
    "area_test = auc(fpr_test, tpr_test)\n",
    "\n",
    "y_score_train = xgbm_final.predict_proba(X_train)[:, 1]\n",
    "fpr_train, tpr_train, thresholds_train = roc_curve(y_train, y_score_train)\n",
    "area_train = auc(fpr_train, tpr_train)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='grey', linestyle='--')\n",
    "plt.plot(fpr_test, tpr_test, label=f'Test ROC curve (AUC = {area_test:.2f})')\n",
    "plt.plot(fpr_train, tpr_train, label=f'Train ROC curve (AUC = {area_train:.2f})')\n",
    "plt.xlim(0.0, 1.0)\n",
    "plt.ylim(0.0, 1.0)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc='lower right')\n",
    "# We can make the plot look nicer by forcing the grid to be square\n",
    "plt.gca().set_aspect('equal', adjustable='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred_proba = xgbm_final.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate the ROC AUC score\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f\"ROC AUC Score: {roc_auc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if XGBoost Is Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on training and validation sets\n",
    "train_preds = xgbm_final.predict(X_train)\n",
    "val_preds = xgbm_final.predict(X_test)\n",
    "\n",
    "# Calculate accuracy scores\n",
    "train_accuracy = accuracy_score(y_train, train_preds)\n",
    "val_accuracy = accuracy_score(y_test, val_preds)\n",
    "\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "# Check for large difference between train and validation accuracy\n",
    "if train_accuracy - val_accuracy > 0.1:\n",
    "    print(\"Warning: The model may be overfitting!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if XGBoost Is Underfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on training and validation sets\n",
    "train_preds = xgbm_final.predict(X_train)\n",
    "val_preds = xgbm_final.predict(X_test)\n",
    "\n",
    "# Calculate MSE for training and validation sets\n",
    "train_mse = mean_squared_error(y_train, train_preds)\n",
    "val_mse = mean_squared_error(y_test, val_preds)\n",
    "\n",
    "print(f\"Training MSE: {train_mse:.4f}\")\n",
    "print(f\"Validation MSE: {val_mse:.4f}\")\n",
    "\n",
    "# Check if both training and validation MSE are high\n",
    "if train_mse > 100 and val_mse > 100:\n",
    "    print(\"Warning: The model may be underfitting!\")\n",
    "    print(\"Consider increasing model complexity by adding more estimators, reducing learning rate, or adjusting other hyperparameters.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BDT Cut Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply BDT to all DataFrames that contain the required Variables\n",
    "for key in DataFrames.keys():\n",
    "    df = DataFrames[key]\n",
    "    \n",
    "    # Check: make sure all input BDT variables exist in this DataFrame\n",
    "    if all(var in df.columns for var in Variables):\n",
    "        # Apply BDT and store the result\n",
    "        DataFrames[key][\"Ds_BkgBDT\"] = uboost_final.predict_proba(df[Variables])[:, 1].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Functions import optimize_cut, plot_save\n",
    "\n",
    "cut = optimize_cut(\n",
    "    df_sig=DataFrames[\"Signal\"],                  # used for plotting signal vs background\n",
    "    df_bkg=DataFrames[\"All\"],\n",
    "    Signal=DataFrames[\"Signal\"],                  # used for FoM numerator (truth-matched signal)\n",
    "    Background=DataFrames[\"All\"],                 # used for FoM denominator (everything else)\n",
    "    var=\"Ds_BkgBDT\",                              # new classifier variable\n",
    "    FoM=\"Ds_BkgBDT\",                              # same as var here\n",
    "    xlabel=\"Background Classifier Output\",\n",
    "    Bins=50,\n",
    "    Range=[0, 1],\n",
    "    varmin=0,\n",
    "    varmax=0.98,\n",
    "    select=\"right\",                               # keep events with higher classifier output\n",
    "    Width=False,\n",
    "    query_signal=\"Ds_isSignal == 1\"\n",
    ")\n",
    "\n",
    "print(f\"Best cut is: {cut:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('default')\n",
    "plt.rcParams.update({\n",
    "    \"axes.labelsize\": 16,\n",
    "    \"xtick.labelsize\": 12,\n",
    "    \"ytick.labelsize\": 12,\n",
    "    \"legend.fontsize\": 16,\n",
    "    \"figure.titlesize\": 20\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suggested Background Break-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stacked = False\n",
    "Density = False\n",
    "Bins = 50\n",
    "# var = 'Ds_diff_D0pi'\n",
    "var = 'Ds_massDifference_0'\n",
    "Range = [0.0, 0.25]\n",
    "BS = 0.82\n",
    "Samples = \"All\"\n",
    "perBin = ((Range[1] - Range[0])/Bins)*1000\n",
    "print(\"Width Per Bin: {width:.2f} MeV\".format(width = perBin))\n",
    "\n",
    "label1= r'$Comb.$'\n",
    "label2= r'$NaN$'\n",
    "label3= r'$D^{*0} \\rightarrow D^{0} \\; \\pi^0 / \\gamma$'\n",
    "label4= r'$D^{*+} \\rightarrow D^{0} \\pi^+$'\n",
    "\n",
    "labels=[label1,label2,label3,label4]\n",
    "colors=[\n",
    "    \"#2E2E2E\",  # Comb. (dark gray-black)\n",
    "    \"#D62728\",  # NaN (dark red)\n",
    "    \"#4C6EB1\",  # D*0 (muted blue)\n",
    "    \"#006400\",  # D*+ → D0π+ (deep green)\n",
    "]\n",
    "df_all = DataFrames[\"All\"][(DataFrames[\"All\"][\"Ds_BkgBDT\"]>=BS)]\n",
    "data = [\n",
    "    df_all[(~df_all[\"Ds_mcPDG\"].isna()) & (abs(df_all[\"Ds_mcPDG\"]) != 413) & (abs(df_all[\"Ds_mcPDG\"]) != 423)][var],\n",
    "    df_all[df_all[\"Ds_mcPDG\"].isna()][var],\n",
    "    df_all[abs(df_all[\"Ds_mcPDG\"]) == 423][var],\n",
    "    df_all[abs(df_all[\"Ds_mcPDG\"]) == 413][var],\n",
    "]\n",
    "\n",
    "# factor = 0.7\n",
    "# plt.hist(DataFrames[\"Signal\"][(DataFrames[\"Signal\"][\"Ds_BkgBDT\"]>=BS)][var], label=\"Signal\", histtype='step', density=Density, bins=Bins, alpha=1, range=Range, weights=factor*np.ones_like(DataFrames[\"Signal\"][(DataFrames[\"Signal\"][\"Ds_BkgBDT\"]>=BS)][var]), ls='--', linewidth=1.5)\n",
    "plt.hist(data, color=colors, label=labels, density=Density, stacked=Stacked, bins=Bins, alpha=1, histtype='step', linewidth=2, range=Range)\n",
    "# plt.axvspan(Range[0],0.16,color='gray',alpha=0.2)\n",
    "# plt.axvline(0.16,ls='--',color='gray')\n",
    "\n",
    "# Title\n",
    "#--------\n",
    "# plt.title(r'$\\bf Generic \\; Events$', loc = \"left\")\n",
    "plt.title(r'$\\bf Generic \\; Events$' + \"\\n\" + r\"$BDT \\geq 0.869$\", loc = \"left\")\n",
    "plt.title(r'$\\int\\mathcal{L}dt\\approx\\;1443.999$ fb$^{-1}$', loc = \"right\")\n",
    "# Label\n",
    "#-------\n",
    "plt.ylabel(r'$Entries/(\\; {width:.2f}\\;MeV/c^2)$'.format(width = perBin))\n",
    "plt.xlabel(r'$\\Delta m_{e}(D_s^{+} - D^{0})\\;[GeV/c^{2}]$')\n",
    "# plt.yscale(\"log\")\n",
    "# plt.xscale(\"log\")\n",
    "# plt.ylim(0, 30000)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stacked = True\n",
    "Density = False\n",
    "Bins = 50\n",
    "# var = 'Ds_diff_D0pi'\n",
    "var = 'Ds_massDifference_0'\n",
    "Range = [0.0, 0.15]\n",
    "BS = 0.828\n",
    "Samples = \"All\"\n",
    "perBin = ((Range[1] - Range[0])/Bins)*1000\n",
    "print(\"Width Per Bin: {width:.2f} MeV\".format(width = perBin))\n",
    "\n",
    "label1= r'$Comb.$'\n",
    "label2= r'$NaN$'\n",
    "label3= r'$D^{*0} \\rightarrow D^{0} \\; \\pi^0 / \\gamma$'\n",
    "label4= r'$D^{*+} \\rightarrow D^{0} \\pi^+$'\n",
    "\n",
    "labels=[label1,label2,label3,label4]\n",
    "colors=[\n",
    "    \"#2E2E2E\",  # Comb. (dark gray-black)\n",
    "    \"#D62728\",  # NaN (dark red)\n",
    "    \"#4C6EB1\",  # D*0 (muted blue)\n",
    "    \"#006400\",  # D*+ → D0π+ (deep green)\n",
    "]\n",
    "df_all = DataFrames[\"All_ReverseID\"][(DataFrames[\"All_ReverseID\"][\"e_electronID\"]<=0.5) & (DataFrames[\"All_ReverseID\"][\"Ds_BkgBDT\"]>=BS)]\n",
    "data = [\n",
    "    df_all[(~df_all[\"Ds_mcPDG\"].isna()) & (abs(df_all[\"Ds_mcPDG\"]) != 413) & (abs(df_all[\"Ds_mcPDG\"]) != 423)][var],\n",
    "    df_all[df_all[\"Ds_mcPDG\"].isna()][var],\n",
    "    df_all[abs(df_all[\"Ds_mcPDG\"]) == 423][var],\n",
    "    df_all[abs(df_all[\"Ds_mcPDG\"]) == 413][var],\n",
    "]\n",
    "\n",
    "# factor = 0.7\n",
    "# plt.hist(DataFrames[\"Signal\"][(DataFrames[\"Signal\"][\"Ds_BkgBDT\"]>=BS)][var], label=\"Signal\", histtype='step', density=Density, bins=Bins, alpha=1, range=Range, weights=factor*np.ones_like(DataFrames[\"Signal\"][(DataFrames[\"Signal\"][\"Ds_BkgBDT\"]>=BS)][var]), ls='--', linewidth=1.5)\n",
    "plt.hist(data, color=colors, label=labels, density=Density, stacked=Stacked, bins=Bins, alpha=1, histtype='step', linewidth=2, range=Range)\n",
    "# plt.axvspan(Range[0],0.16,color='gray',alpha=0.2)\n",
    "# plt.axvline(0.16,ls='--',color='gray')\n",
    "\n",
    "# Title\n",
    "#--------\n",
    "# plt.title(r'$\\bf Generic \\; Events$', loc = \"left\")\n",
    "plt.title(r'$\\bf Generic \\; Events$' + \"\\n\" + r\"$BDT \\geq 0.869$\", loc = \"left\")\n",
    "plt.title(r'$\\int\\mathcal{L}dt\\approx\\;1443.999$ fb$^{-1}$', loc = \"right\")\n",
    "# Label\n",
    "#-------\n",
    "plt.ylabel(r'$Entries/(\\; {width:.2f}\\;MeV/c^2)$'.format(width = perBin))\n",
    "plt.xlabel(r'$\\Delta m_{e}(D_s^{+} - D^{0})\\;[GeV/c^{2}]$')\n",
    "# plt.yscale(\"log\")\n",
    "# plt.xscale(\"log\")\n",
    "# plt.ylim(0, 30000)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bins=50\n",
    "Density = False\n",
    "Stacked = True\n",
    "Range = [0.0,0.25]\n",
    "BS = -1\n",
    "perBin = ((Range[1] - Range[0])/Bins)*1000\n",
    "# var = 'Ds_diff_D0pi'\n",
    "var = 'Ds_massDifference_0'\n",
    "print(\"Width Per Bin: {width:.2f} MeV\".format(width = perBin))\n",
    "\n",
    "label1= r'$isSignal(D_s^{+})=1$'\n",
    "label2= r'$isSignal(D_s^{+})=0$'\n",
    "label3= r'$NaN$'\n",
    "\n",
    "labels=[label1,label2,label3]\n",
    "colors=['#7eb0d5','#fd7f6f','purple']\n",
    "\n",
    "data = [DataFrames[\"Signal\"][(DataFrames[\"Signal\"]['Ds_isSignal']==1) & (DataFrames[\"Signal\"][\"Ds_BkgBDT\"]>=BS)][var],\n",
    "        DataFrames[\"Signal\"][(DataFrames[\"Signal\"]['Ds_isSignal']==0) & (DataFrames[\"Signal\"][\"Ds_BkgBDT\"]>=BS)][var],\n",
    "        DataFrames[\"Signal\"][(DataFrames[\"Signal\"]['Ds_isSignal'].isna()) & (DataFrames[\"Signal\"][\"Ds_BkgBDT\"]>=BS)][var]\n",
    "       ]\n",
    "\n",
    "\n",
    "plt.hist(data[::-1], color=colors[::-1], label=labels[::-1], alpha=1, range=Range, linewidth=2, stacked=Stacked, density=Density, bins=Bins, histtype='step')\n",
    "# plt.axvspan(Range[0],0.16,color='gray',alpha=0.2)\n",
    "# plt.axvline(0.16,ls='--',color='gray')\n",
    "\n",
    "# Title\n",
    "#---------\n",
    "# Signal\n",
    "# plt.title(r'$2M\\;Events$', loc = \"left\")\n",
    "plt.title(r'$2M\\;Events$'+\"\\n\"+r\"$BDT \\geq 0.525$\", loc = \"left\")\n",
    "plt.title(r'$\\bf Signal\\;Events$', loc = \"right\")\n",
    "# # Background\n",
    "# plt.title(r'$\\int\\mathcal{L}dt\\approx\\;100$ fb$^{-1}$', loc = \"left\")\n",
    "# plt.title(r'$\\bf Generic\\;c\\bar{c}\\;Events$', loc = \"right\")\n",
    "# Label\n",
    "#---------\n",
    "plt.ylabel(r'$Entries/(\\; {width:.2f}\\;MeV/c^2)$'.format(width = perBin))\n",
    "plt.xlabel(r'$\\Delta m_{e}(D_s^{+} - D^{0})\\;[GeV/c^{2}]$')\n",
    "# plt.yscale(\"log\") \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save BDT Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct Charge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import uproot\n",
    "# import numpy as np  # Make sure this is imported if you're working in a standalone script\n",
    "\n",
    "# # === Samples to process ===\n",
    "# samples = [\"Signal\", \"BB\", \"ccbar\", \"ddbar\", \"ssbar\", \"taupair\", \"uubar\"]\n",
    "\n",
    "# # === Output directory for new Bkg BDT files ===\n",
    "# output_dir = \"/group/belle/users/amubarak/03-ML/BkgBDT/\"\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# # === Base input info used to construct filenames ===\n",
    "# base_input_dir = \"/group/belle/users/amubarak/02-Grid/Sample_Grid\"\n",
    "# Date = \"0530\"\n",
    "# Attempt = \"0\"\n",
    "\n",
    "# # === Loop over samples and write output ROOT files ===\n",
    "# for s in samples:\n",
    "#     if s not in DataFrames:\n",
    "#         print(f\"Warning: {s} not in DataFrames — skipping.\")\n",
    "#         continue\n",
    "\n",
    "#     # Convert Ds_BkgBDT to float32 if present\n",
    "#     if \"Ds_BkgBDT\" in DataFrames[s].columns:\n",
    "#         DataFrames[s][\"Ds_BkgBDT\"] = DataFrames[s][\"Ds_BkgBDT\"].astype(np.float32)\n",
    "\n",
    "#     # Construct the original file name\n",
    "#     if s == \"Signal\":\n",
    "#         original_name = \"Ds2D0enu-Signal.root\"\n",
    "#     else:\n",
    "#         original_name = f\"Ds2D0e-Generic_Ds_{Date}25_{Attempt}_{s}.root\"\n",
    "\n",
    "#     # Build output file name with BkgBDT tag\n",
    "#     output_name = original_name.replace(\".root\", \"_withBkgBDT.root\")\n",
    "#     out_path = os.path.join(output_dir, output_name)\n",
    "\n",
    "#     # Save DataFrame to ROOT\n",
    "#     with uproot.recreate(out_path) as f:\n",
    "#         f[\"Dstree\"] = DataFrames[s]\n",
    "\n",
    "#     print(f\"Saved: {out_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrong Charge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import uproot\n",
    "# import numpy as np  # Required for dtype conversion\n",
    "\n",
    "# # === Define wrong-charge samples ===\n",
    "# samples_WCh = [\"Signal_WCh\", \"BB_WCh\", \"ccbar_WCh\", \"ddbar_WCh\", \"ssbar_WCh\", \"taupair_WCh\", \"uubar_WCh\", \"Data_WCh\"]\n",
    "\n",
    "# # === Output directory for BkgBDT files (wrong charge) ===\n",
    "# output_dir_WCh = \"/group/belle/users/amubarak/03-ML/BkgBDT_WCh/\"\n",
    "# os.makedirs(output_dir_WCh, exist_ok=True)\n",
    "\n",
    "# # === Base input path for wrong-charge files ===\n",
    "# base_input_dir_WCh = \"/group/belle/users/amubarak/02-Grid/Sample_Grid_WCh\"\n",
    "# Date_WCh = \"0530\"\n",
    "# Attempt_WCh = \"0\"\n",
    "\n",
    "# # === Save each wrong-charge DataFrame with updated Ds_BkgBDT ===\n",
    "# for s in samples_WCh:\n",
    "#     if s not in DataFrames:\n",
    "#         print(f\"Warning: {s} not in DataFrames — skipping.\")\n",
    "#         continue\n",
    "\n",
    "#     # Convert Ds_BkgBDT to float32 if present\n",
    "#     if \"Ds_BkgBDT\" in DataFrames[s].columns:\n",
    "#         DataFrames[s][\"Ds_BkgBDT\"] = DataFrames[s][\"Ds_BkgBDT\"].astype(np.float32)\n",
    "\n",
    "#     # Set original file name\n",
    "#     if s == \"Signal_WCh\":\n",
    "#         original_name = \"Ds2D0enu-Signal_WCh.root\"\n",
    "#     else:\n",
    "#         tag = s.replace(\"_WCh\", \"\")\n",
    "#         original_name = f\"Ds2D0e-Generic_Ds_{Date_WCh}25_{Attempt_WCh}_{tag}.root\"\n",
    "\n",
    "#     # Build output path with _withBkgBDT suffix\n",
    "#     output_name = original_name.replace(\".root\", \"_withBkgBDT.root\")\n",
    "#     out_path = os.path.join(output_dir_WCh, output_name)\n",
    "\n",
    "#     # Save DataFrame to ROOT\n",
    "#     with uproot.recreate(out_path) as f:\n",
    "#         f[\"Dstree\"] = DataFrames[s]\n",
    "\n",
    "#     print(f\"Saved: {out_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reverse PID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import uproot\n",
    "# import numpy as np  # Ensure this is available for dtype conversion\n",
    "\n",
    "# # === Define ReverseID samples ===\n",
    "# samples_ReverseID = [\"Signal_ReverseID\", \"BB_ReverseID\", \"ccbar_ReverseID\", \"ddbar_ReverseID\", \"ssbar_ReverseID\", \"taupair_ReverseID\", \"uubar_ReverseID\", \"Data_ReverseID\"]\n",
    "\n",
    "# # === Output directory for BkgBDT ReverseID files ===\n",
    "# output_dir_ReverseID = \"/group/belle/users/amubarak/03-ML/BkgBDT_ReverseID/\"\n",
    "# os.makedirs(output_dir_ReverseID, exist_ok=True)\n",
    "\n",
    "# # === Base input path for ReverseID ===\n",
    "# base_input_dir_ReverseID = \"/group/belle/users/amubarak/02-Grid/Sample_Grid_ReverseID\"\n",
    "# Date_ReverseID = \"0530\"\n",
    "# Attempt_ReverseID = \"0\"\n",
    "\n",
    "# # === Save each ReverseID DataFrame with Ds_BkgBDT ===\n",
    "# for s in samples_ReverseID:\n",
    "#     if s not in DataFrames:\n",
    "#         print(f\"Warning: {s} not in DataFrames — skipping.\")\n",
    "#         continue\n",
    "\n",
    "#     # Convert Ds_BkgBDT to float32 if present\n",
    "#     if \"Ds_BkgBDT\" in DataFrames[s].columns:\n",
    "#         DataFrames[s][\"Ds_BkgBDT\"] = DataFrames[s][\"Ds_BkgBDT\"].astype(np.float32)\n",
    "\n",
    "#     # Set original file name\n",
    "#     if s == \"Signal_ReverseID\":\n",
    "#         original_name = \"Ds2D0enu-Signal_ReverseID.root\"\n",
    "#     else:\n",
    "#         tag = s.replace(\"_ReverseID\", \"\")\n",
    "#         original_name = f\"Ds2D0e-Generic_Ds_{Date_ReverseID}25_{Attempt_ReverseID}_{tag}.root\"\n",
    "\n",
    "#     # Build output file name with _withBkgBDT suffix\n",
    "#     output_name = original_name.replace(\".root\", \"_withBkgBDT.root\")\n",
    "#     out_path = os.path.join(output_dir_ReverseID, output_name)\n",
    "\n",
    "#     # Save DataFrame to ROOT\n",
    "#     with uproot.recreate(out_path) as f:\n",
    "#         f[\"Dstree\"] = DataFrames[s]\n",
    "\n",
    "#     print(f\"Saved: {out_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reverse PID and Wrong Charge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uproot\n",
    "import numpy as np  # Ensure this is available for dtype conversion\n",
    "\n",
    "# === Define ReverseID samples ===\n",
    "samples_ReverseID_WCh = [\"All_ReverseID_WCh\", \"BB_ReverseID_WCh\", \"ccbar_ReverseID_WCh\", \"ddbar_ReverseID_WCh\", \"ssbar_ReverseID_WCh\", \"taupair_ReverseID_WCh\", \"uubar_ReverseID_WCh\", \"uds_ReverseID_WCh\", \"Data_ReverseID_WCh\"]\n",
    "\n",
    "# === Output directory for BkgBDT ReverseID files ===\n",
    "output_dir_ReverseID_WCh = \"/group/belle/users/amubarak/03-ML/BkgBDT_ReverseID_WCh/\"\n",
    "os.makedirs(output_dir_ReverseID_WCh, exist_ok=True)\n",
    "\n",
    "# === Base input path for ReverseID ===\n",
    "base_input_dir_ReverseID_WCh = \"/group/belle/users/amubarak/02-Grid/Sample_Grid_ReverseID_WCh\"\n",
    "Date_ReverseID_WCh = \"0530\"\n",
    "Attempt_ReverseID_WCh = \"0\"\n",
    "\n",
    "# === Save each ReverseID DataFrame with Ds_BkgBDT ===\n",
    "for s in samples_ReverseID_WCh:\n",
    "    if s not in DataFrames:\n",
    "        print(f\"Warning: {s} not in DataFrames — skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Convert Ds_BkgBDT to float32 if present\n",
    "    if \"Ds_BkgBDT\" in DataFrames[s].columns:\n",
    "        DataFrames[s][\"Ds_BkgBDT\"] = DataFrames[s][\"Ds_BkgBDT\"].astype(np.float32)\n",
    "\n",
    "    # Set original file name\n",
    "    if s == \"Signal_ReverseID_WCh\":\n",
    "        original_name = \"Ds2D0enu-Signal_ReverseID_WCh.root\"\n",
    "    else:\n",
    "        tag = s.replace(\"_ReverseID_WCh\", \"\")\n",
    "        original_name = f\"Ds2D0e-Generic_Ds_{Date_ReverseID_WCh}25_{Attempt_ReverseID_WCh}_{tag}.root\"\n",
    "\n",
    "    # Build output file name with _withBkgBDT suffix\n",
    "    output_name = original_name.replace(\".root\", \"_withBkgBDT.root\")\n",
    "    out_path = os.path.join(output_dir_ReverseID_WCh, output_name)\n",
    "\n",
    "    # Save DataFrame to ROOT\n",
    "    with uproot.recreate(out_path) as f:\n",
    "        f[\"Dstree\"] = DataFrames[s]\n",
    "\n",
    "    print(f\"Saved: {out_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Belle2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
