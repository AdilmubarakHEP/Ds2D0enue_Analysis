{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall -y scikit-learn\n",
    "# !pip install scikit-learn==1.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install --upgrade pip\n",
    "# ! pip install torch\n",
    "# ! pip install hiddenlayer\n",
    "# ! pip install --user bayesian-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mplhep\n",
    "import sys\n",
    "\n",
    "import seaborn as sns\n",
    "import pydot\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import uproot\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.datasets import make_classification,make_regression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import auc,roc_curve,confusion_matrix,classification_report,precision_recall_curve,mean_squared_error,accuracy_score,roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV, cross_validate, validation_curve,train_test_split,KFold,learning_curve,cross_val_score\n",
    "from scipy.stats import ks_2samp\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.utils import class_weight\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\n",
    "    \"axes.labelsize\": 16,\n",
    "    \"xtick.labelsize\": 12,\n",
    "    \"ytick.labelsize\": 12,\n",
    "    \"legend.fontsize\": 12,\n",
    "    \"figure.titlesize\": 18\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/home/belle2/amubarak/Ds2D0enue_Analysis/07-Python_Functions/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep-Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uproot\n",
    "import pandas as pd\n",
    "\n",
    "# === Load only selected branches ===\n",
    "with open(\"/home/belle2/amubarak/Ds2D0enue_Analysis/03-Grid/Save_var.txt\") as f:\n",
    "    variables_to_load = [\n",
    "        line.strip().strip(\",\").strip('\"').strip(\"'\")\n",
    "        for line in f\n",
    "        if line.strip() and not line.strip().startswith(\"#\")\n",
    "    ]\n",
    "\n",
    "# Make sure to include BDT output variable\n",
    "if \"Ds_FakeD0BDT\" not in variables_to_load:\n",
    "    variables_to_load.append(\"Ds_FakeD0BDT\")\n",
    "\n",
    "# === Sample list ===\n",
    "samples = [\"Signal\", \"BB\", \"ccbar\", \"ddbar\", \"ssbar\", \"taupair\", \"uubar\"]\n",
    "GenEvents = samples.copy()\n",
    "\n",
    "# === Input configuration ===\n",
    "Date = \"0530\"\n",
    "Attempt = \"0\"\n",
    "input_dir = \"/group/belle2/users2022/amubarak/03-ML/FakeD0/\"\n",
    "\n",
    "# === Load ROOT files into DataFrames ===\n",
    "DataFrames = {}\n",
    "\n",
    "for s in samples:\n",
    "    if s == \"Signal\":\n",
    "        file_path = os.path.join(input_dir, \"Ds2D0enu-Signal_withBDT.root\")\n",
    "    else:\n",
    "        file_path = os.path.join(\n",
    "            input_dir, f\"Ds2D0e-Generic_Ds_{Date}25_{Attempt}_{s}_withBDT.root\"\n",
    "        )\n",
    "\n",
    "    print(f\"Loading: {file_path}\")\n",
    "    DataFrames[s] = uproot.concatenate(\n",
    "        f\"{file_path}:Dstree\",\n",
    "        filter_name=variables_to_load,\n",
    "        library=\"pd\"\n",
    "    )\n",
    "\n",
    "# === Define combined background ===\n",
    "background_samples = [\"BB\", \"ccbar\", \"ddbar\", \"ssbar\", \"taupair\", \"uubar\"]\n",
    "DataFrames[\"All\"] = pd.concat([DataFrames[s] for s in background_samples], ignore_index=True)\n",
    "\n",
    "# === Combine uds backgrounds for convenience ===\n",
    "DataFrames[\"uds\"] = pd.concat(\n",
    "    [DataFrames[\"uubar\"], DataFrames[\"ddbar\"], DataFrames[\"ssbar\"]],\n",
    "    ignore_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 200000)\n",
    "pd.set_option('display.max_columns', 200000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The line below is to look at the available variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrames[\"All\"].columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "The code below will be used to apply cuts to the data.  \n",
    "The range of the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Electron ID\n",
    "#-------------------\n",
    "# DataFrames[\"Signal\"] = DataFrames[\"Signal\"][DataFrames[\"Signal\"]['e_electronID']>=0.95]\n",
    "# DataFrames[\"ccbar\"] = DataFrames[\"ccbar\"][DataFrames[\"ccbar\"]['e_electronID']>=0.95]\n",
    "# DataFrames[\"Signal\"] = DataFrames[\"Signal\"][DataFrames[\"Signal\"]['Ds_gammaveto_em_electronID']>=0.95]\n",
    "# DataFrames[\"ccbar\"] = DataFrames[\"ccbar\"][DataFrames[\"ccbar\"]['Ds_gammaveto_em_electronID']>=0.95]\n",
    "\n",
    "# Photon Conversion\n",
    "#-------------------\n",
    "# DataFrames[samples[0]] = DataFrames[samples[0]][DataFrames[samples[0]]['Ds_gammaveto_M_Correction']>=0.1]\n",
    "# DataFrames[samples[1]] = DataFrames[samples[1]][DataFrames[samples[1]]['Ds_gammaveto_M_Correction']>=0.1]\n",
    "\n",
    "# Peaking Background Removal\n",
    "#----------------------------\n",
    "# DataFrames[\"ccbar\"] = DataFrames[\"ccbar\"][(DataFrames[\"ccbar\"]['Ds_diff_D0pi']>=0.15)]\n",
    "# DataFrames[\"Signal\"] = DataFrames[\"Signal\"][(DataFrames[\"Signal\"]['Ds_diff_D0pi']>=0.15)]\n",
    "\n",
    "# # Vertex Fitting\n",
    "# #----------------\n",
    "# DataFrames[\"Signal\"] = DataFrames[\"Signal\"][DataFrames[\"Signal\"]['Ds_chiProb']>=0.01]\n",
    "# DataFrames[\"ccbar\"] = DataFrames[\"ccbar\"][DataFrames[\"ccbar\"]['Ds_chiProb']>=0.01]\n",
    "\n",
    "# Dalitz Removal\n",
    "#----------------------------\n",
    "# DataFrames[\"ccbar\"] = DataFrames[\"ccbar\"][(DataFrames[\"ccbar\"]['Ds_pi0veto_M_Correction']<=0.08) | (DataFrames[\"ccbar\"]['Ds_pi0veto_M_Correction']>=0.16)]\n",
    "# DataFrames[\"Signal\"] = DataFrames[\"Signal\"][(DataFrames[\"Signal\"]['Ds_pi0veto_M_Correction']<=0.08) | (DataFrames[\"Signal\"]['Ds_pi0veto_M_Correction']>=0.16)]\n",
    "\n",
    "# Vertex Fit\n",
    "#----------------\n",
    "# DataFrames[samples[0]] = DataFrames[samples[0]][DataFrames[samples[0]]['Ds_chiProb_rank']==1]\n",
    "# DataFrames[samples[1]] = DataFrames[samples[1]][DataFrames[samples[1]]['Ds_chiProb_rank']==1]\n",
    "\n",
    "# D0 Invariant Mass\n",
    "#-----------------------\n",
    "# DataFrames[samples[0]] = DataFrames[samples[0]][(DataFrames[samples[0]]['Ds_D0_sideband']==1)]\n",
    "# DataFrames[samples[1]] = DataFrames[samples[1]][(DataFrames[samples[1]]['Ds_D0_sideband']==1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $D^{*+}$ Suppression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Settings ===\n",
    "Stacked = True\n",
    "Density = False\n",
    "Bins = 50\n",
    "Range = [0.0, 0.25]\n",
    "perBin = ((Range[1] - Range[0]) / Bins) * 1000\n",
    "print(\"Width Per Bin: {:.2f} MeV\".format(perBin))\n",
    "\n",
    "# Cut range on 'Ds_diff_D0pi'\n",
    "cut_low = 0.142\n",
    "cut_high = 0.15\n",
    "\n",
    "# Variable to plot after cut\n",
    "var = 'Ds_massDifference_0'\n",
    "\n",
    "# Labels and colors\n",
    "labels = [\n",
    "    r'$c \\bar{c}$',\n",
    "    r'$u \\bar{u}, \\; d \\bar{d}, \\;s \\bar{s}$',\n",
    "    r'$BB$',\n",
    "    r'$\\tau^{+} \\tau^{-}$'\n",
    "]\n",
    "\n",
    "# Apply sideband cut (outside signal region) and collect data\n",
    "data = [\n",
    "    DataFrames[\"ccbar\"].query(\"Ds_diff_D0pi <= @cut_low or Ds_diff_D0pi >= @cut_high\")[var],\n",
    "    DataFrames[\"uds\"].query(\"Ds_diff_D0pi <= @cut_low or Ds_diff_D0pi >= @cut_high\")[var],\n",
    "    DataFrames[\"BB\"].query(\"Ds_diff_D0pi <= @cut_low or Ds_diff_D0pi >= @cut_high\")[var],\n",
    "    DataFrames[\"taupair\"].query(\"Ds_diff_D0pi <= @cut_low or Ds_diff_D0pi >= @cut_high\")[var],\n",
    "]\n",
    "\n",
    "# === Plot ===\n",
    "# plt.figure(figsize=(8, 5))\n",
    "plt.hist(data[::-1],\n",
    "         label=labels[::-1],\n",
    "         density=Density,\n",
    "         stacked=Stacked,\n",
    "         bins=Bins,\n",
    "         range=Range,\n",
    "         histtype='step',\n",
    "         linewidth=2)\n",
    "\n",
    "# Titles\n",
    "plt.title(r'$D_s^{+} \\rightarrow [D^{0} \\rightarrow K^{-} \\pi^{+}] e^{+} \\nu_{e}$' + '\\n' + r'$\\Delta m_{\\pi}(D_s^{+} - D^{0}) \\notin [0.142,\\; 0.15] \\; \\mathrm{GeV}/c^{2}$', loc=\"left\")\n",
    "plt.title(r'$\\int\\mathcal{L}dt\\approx\\;1444$ fb$^{-1}$', loc=\"right\")\n",
    "\n",
    "# Labels\n",
    "plt.xlabel(r'$\\Delta m_{e}(D_s^{+} - D^{0})\\;[GeV/c^{2}]$')\n",
    "plt.ylabel(r'$Entries/(\\;{:.2f}\\;MeV/c^2)$'.format(perBin))\n",
    "plt.legend()\n",
    "# plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Settings ===\n",
    "Stacked = True\n",
    "Density = False\n",
    "Bins = 50\n",
    "Range = [0.0, 0.25]\n",
    "perBin = ((Range[1] - Range[0]) / Bins) * 1000\n",
    "print(\"Width Per Bin: {:.2f} MeV\".format(perBin))\n",
    "\n",
    "# Data source and variables\n",
    "df_cut = DataFrames[\"All\"]\n",
    "cut_var = \"Ds_diff_D0pi\"\n",
    "plot_var = 'Ds_massDifference_0'\n",
    "pdg_var = 'Ds_mcPDG'\n",
    "\n",
    "# === Categories based on true Ds_mcPDG ===\n",
    "dstar_plus = df_cut[abs(df_cut[pdg_var]) == 413][plot_var]\n",
    "dstar_zero = df_cut[abs(df_cut[pdg_var]) == 423][plot_var]\n",
    "other = df_cut[(abs(df_cut[pdg_var]) != 413) & (abs(df_cut[pdg_var]) != 423)][plot_var]\n",
    "\n",
    "# === Plot ===\n",
    "plt.hist([other, dstar_zero, dstar_plus],\n",
    "         color=[\"#2E2E2E\", \"#4C6EB1\", \"#007C91\"],\n",
    "         label=[\"Other\", r\"$D^{*0}$\", r\"$D^{*+}$\"],\n",
    "         density=Density,\n",
    "         stacked=Stacked,\n",
    "         bins=Bins,\n",
    "         range=Range,\n",
    "         histtype='step',\n",
    "         linewidth=2)\n",
    "\n",
    "# Titles and labels\n",
    "plt.title(r'$D_s^{+} \\rightarrow [D^{0} \\rightarrow K^{-} \\pi^{+}] e^{+} \\nu_{e}$', loc=\"left\")\n",
    "plt.title(r'$\\int\\mathcal{L}dt\\approx\\;1444$ fb$^{-1}$', loc=\"right\")\n",
    "plt.xlabel(r'$\\Delta m_{e}(D_s^{+} - D^{0})\\;[GeV/c^{2}]$')\n",
    "plt.ylabel(r'$Entries/(\\;{:.2f}\\;MeV/c^2)$'.format(perBin))\n",
    "plt.legend()\n",
    "# plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Settings ===\n",
    "Stacked = True\n",
    "Density = False\n",
    "Bins = 50\n",
    "Range = [0.0, 0.25]\n",
    "perBin = ((Range[1] - Range[0]) / Bins) * 1000\n",
    "print(\"Width Per Bin: {:.2f} MeV\".format(perBin))\n",
    "\n",
    "# Data source and variables\n",
    "df = DataFrames[\"All\"]\n",
    "cut_var = \"Ds_diff_D0pi\"\n",
    "plot_var = 'Ds_massDifference_0'\n",
    "pdg_var = 'Ds_mcPDG'\n",
    "\n",
    "# Sideband cut (exclude D*⁺ peak)\n",
    "cut_low = 0.142\n",
    "cut_high = 0.15\n",
    "df_cut = df.query(f\"{cut_var} <= @cut_low or {cut_var} >= @cut_high\")\n",
    "\n",
    "# === Categories based on true Ds_mcPDG ===\n",
    "dstar_plus = df_cut[abs(df_cut[pdg_var]) == 413][plot_var]\n",
    "dstar_zero = df_cut[abs(df_cut[pdg_var]) == 423][plot_var]\n",
    "other = df_cut[(abs(df_cut[pdg_var]) != 413) & (abs(df_cut[pdg_var]) != 423)][plot_var]\n",
    "\n",
    "# === Plot ===\n",
    "plt.hist([other, dstar_zero, dstar_plus],\n",
    "         color=[\"#2E2E2E\", \"#4C6EB1\", \"#007C91\"],\n",
    "         label=[\"Other\", r\"$D^{*0}$\", r\"$D^{*+}$\"],\n",
    "         density=Density,\n",
    "         stacked=Stacked,\n",
    "         bins=Bins,\n",
    "         range=Range,\n",
    "         histtype='step',\n",
    "         linewidth=2)\n",
    "\n",
    "# Titles and labels\n",
    "plt.title(r'$D_s^{+} \\rightarrow [D^{0} \\rightarrow K^{-} \\pi^{+}] e^{+} \\nu_{e}$' + '\\n' +\n",
    "          r'$\\Delta m_{\\pi}(D_s^{+} - D^{0}) \\notin [0.142,\\; 0.15] \\; \\mathrm{GeV}/c^{2}$', loc=\"left\")\n",
    "plt.title(r'$\\int\\mathcal{L}dt\\approx\\;1444$ fb$^{-1}$', loc=\"right\")\n",
    "plt.xlabel(r'$\\Delta m_{e}(D_s^{+} - D^{0})\\;[GeV/c^{2}]$')\n",
    "plt.ylabel(r'$Entries/(\\;{:.2f}\\;MeV/c^2)$'.format(perBin))\n",
    "plt.legend()\n",
    "# plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Settings ===\n",
    "Stacked = True\n",
    "Density = False\n",
    "Bins = 50\n",
    "Range = [0.0, 0.25]\n",
    "perBin = ((Range[1] - Range[0]) / Bins) * 1000\n",
    "print(\"Width Per Bin: {:.2f} MeV\".format(perBin))\n",
    "\n",
    "# Data source and variables\n",
    "df = DataFrames[\"All\"]\n",
    "cut_var = \"Ds_diff_D0pi\"\n",
    "plot_var = 'Ds_massDifference_0'\n",
    "pdg_var = 'Ds_mcPDG'\n",
    "\n",
    "# Sideband cut (exclude D*⁺ peak)\n",
    "cut_low = 0.142\n",
    "cut_high = 0.15\n",
    "df_cut = df.query(f\"{cut_var} <= @cut_low or {cut_var} >= @cut_high\")\n",
    "\n",
    "# === Categories based on true Ds_mcPDG ===\n",
    "dstar_plus = df_cut[abs(df_cut[pdg_var]) == 413][plot_var]\n",
    "dstar_zero = df_cut[abs(df_cut[pdg_var]) == 423][plot_var]\n",
    "other = df_cut[(abs(df_cut[pdg_var]) != 413) & (abs(df_cut[pdg_var]) != 423)][plot_var]\n",
    "\n",
    "# === Plot with D*+ in the middle ===\n",
    "plt.hist([other, dstar_plus, dstar_zero],  # <== reordered\n",
    "         color=[\"#2E2E2E\", \"#007C91\", \"#4C6EB1\"],\n",
    "         label=[\"Other\", r\"$D^{*+}$\", r\"$D^{*0}$\"],\n",
    "         density=Density,\n",
    "         stacked=Stacked,\n",
    "         bins=Bins,\n",
    "         range=Range,\n",
    "         histtype='step',\n",
    "         linewidth=2)\n",
    "\n",
    "# Titles and labels\n",
    "plt.title(r'$D_s^{+} \\rightarrow [D^{0} \\rightarrow K^{-} \\pi^{+}] e^{+} \\nu_{e}$' + '\\n' +\n",
    "          r'$\\Delta m_{\\pi}(D_s^{+} - D^{0}) \\notin [0.142,\\; 0.15] \\; \\mathrm{GeV}/c^{2}$', loc=\"left\")\n",
    "plt.title(r'$\\int\\mathcal{L}dt\\approx\\;1444$ fb$^{-1}$', loc=\"right\")\n",
    "plt.xlabel(r'$\\Delta m_{e}(D_s^{+} - D^{0})\\;[GeV/c^{2}]$')\n",
    "plt.ylabel(r'$Entries/(\\;{:.2f}\\;MeV/c^2)$'.format(perBin))\n",
    "plt.legend()\n",
    "# plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2d_with_marginals(df, xvar, yvar, xrange=None, yrange=None, bins=50, title=None):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.gridspec as gridspec\n",
    "    import pandas as pd\n",
    "\n",
    "    # Extract variables\n",
    "    x = df[xvar]\n",
    "    y = df[yvar]\n",
    "\n",
    "    # Apply range cuts\n",
    "    if xrange is not None:\n",
    "        xmask = (x >= xrange[0]) & (x <= xrange[1])\n",
    "    else:\n",
    "        xmask = pd.Series([True] * len(x))\n",
    "\n",
    "    if yrange is not None:\n",
    "        ymask = (y >= yrange[0]) & (y <= yrange[1])\n",
    "    else:\n",
    "        ymask = pd.Series([True] * len(y))\n",
    "\n",
    "    mask = xmask & ymask\n",
    "    x = x[mask]\n",
    "    y = y[mask]\n",
    "\n",
    "    # === Adjusted GridSpec ===\n",
    "    fig = plt.figure(figsize=(7, 7))\n",
    "    gs = gridspec.GridSpec(6, 6, hspace=0.05, wspace=0.05)  # More divisions\n",
    "\n",
    "    ax_main = fig.add_subplot(gs[2:6, 0:4])\n",
    "    ax_xhist = fig.add_subplot(gs[0:2, 0:4], sharex=ax_main)  # Taller top histogram\n",
    "    ax_yhist = fig.add_subplot(gs[2:6, 4:6], sharey=ax_main)  # Wider side histogram\n",
    "    ax_cbar = fig.add_subplot(gs[0:2, 4:6])  # Optional: move cbar if needed\n",
    "\n",
    "    # Histogram range\n",
    "    hist_range = [xrange, yrange] if xrange and yrange else None\n",
    "\n",
    "    # 2D histogram\n",
    "    counts, xedges, yedges, im = ax_main.hist2d(x, y, bins=bins, range=hist_range, cmap=\"viridis\")\n",
    "    cbar = fig.colorbar(im, cax=ax_cbar)\n",
    "    cbar.set_label(\"Entries\")\n",
    "\n",
    "    # Marginal histograms\n",
    "    ax_xhist.hist(x, bins=bins, range=xrange, color=\"#2E2E2E\", histtype='step', linewidth=1.5)\n",
    "    ax_yhist.hist(y, bins=bins, range=yrange, orientation=\"horizontal\", color=\"#007C91\", histtype='step', linewidth=1.5)\n",
    "\n",
    "    # Labels\n",
    "    ax_main.set_xlabel(r'$\\Delta m_{e}(D_s^{+} - D^{0})\\;[GeV/c^{2}]$')\n",
    "    ax_main.set_ylabel(r'$\\Delta m_{\\pi}(D_s^{+} - D^{0})\\;[GeV/c^{2}]$')\n",
    "    ax_xhist.set_ylabel(\"Entries\")\n",
    "    ax_yhist.set_xlabel(\"Entries\")\n",
    "\n",
    "    # Clean ticks\n",
    "    plt.setp(ax_xhist.get_xticklabels(), visible=False)\n",
    "    plt.setp(ax_yhist.get_yticklabels(), visible=False)\n",
    "\n",
    "    ax_yhist.set_xticklabels([\n",
    "        \"\" if np.isclose(t, 0) else f\"{int(t)}\" for t in ax_yhist.get_xticks()\n",
    "    ])\n",
    "\n",
    "    # Title\n",
    "    if title:\n",
    "        plt.suptitle(title, fontsize=20)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_2d_with_marginals(DataFrames[\"All\"][(abs(DataFrames[\"All\"][\"Ds_mcPDG\"])==423)],\n",
    "#     xvar=\"Ds_massDifference_0\",\n",
    "#     yvar=\"Ds_diff_D0pi\",\n",
    "#     xrange=(0.0, 0.25),\n",
    "#     yrange=(0.1, 0.55),\n",
    "#     bins=60,\n",
    "#     title=r\"$\\bf Generic \\; Events$\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_2d_with_marginals(DataFrames[\"All\"],\n",
    "#     xvar=\"Ds_massDifference_0\",\n",
    "#     yvar=\"Ds_diff_D0pi\",\n",
    "#     xrange=(0.0, 0.25),\n",
    "#     yrange=(0.1, 0.55),\n",
    "#     bins=60,\n",
    "#     title=r\"$\\bf Generic \\; Events$\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stacked = True\n",
    "Density = True\n",
    "Bins = 50\n",
    "i = 'Ds_massDifference_0'\n",
    "# i = 'Ds_diff_D0pi'\n",
    "Range = [0.0,0.25]\n",
    "dM = -1\n",
    "BD = -1\n",
    "perBin = ((Range[1] - Range[0])/Bins)*1000\n",
    "print(\"Width Per Bin: {width:.2f} MeV\".format(width = perBin))\n",
    "\n",
    "label1= r'$D^{*0} \\rightarrow D^{0} [\\gamma \\rightarrow  e^{+} e^{-}]$'\n",
    "label2= r'$D^{*0} \\rightarrow D^{0} [\\pi^0 \\rightarrow \\gamma [\\gamma \\rightarrow e^{+} e^{-}]]$'\n",
    "label3= r'$D^{*0} \\rightarrow D^{0} [\\pi^0 \\rightarrow \\gamma  e^{+} e^{-}]$'\n",
    "\n",
    "labels=[label1,label2,label3]\n",
    "data=[\n",
    "      DataFrames[\"All\"][(abs(DataFrames[\"All\"]['Ds_mcPDG'])==423) & (abs(DataFrames[\"All\"]['Ds_genNStepsToDaughter_1'])==2) & (abs(DataFrames[\"All\"]['e_genMotherPDG'])==22) & (DataFrames[\"All\"]['Ds_gammaveto_M_Correction']>=dM)][i],\n",
    "      DataFrames[\"All\"][(abs(DataFrames[\"All\"]['Ds_mcPDG'])==423) & (abs(DataFrames[\"All\"]['Ds_genNStepsToDaughter_1'])==3) & (abs(DataFrames[\"All\"]['e_genMotherPDG'])==22) & (DataFrames[\"All\"]['Ds_gammaveto_M_Correction']>=dM)][i],\n",
    "      DataFrames[\"All\"][(abs(DataFrames[\"All\"]['Ds_mcPDG'])==423) & (abs(DataFrames[\"All\"]['Ds_genNStepsToDaughter_1'])==2) & (abs(DataFrames[\"All\"]['e_genMotherPDG'])==111) & (DataFrames[\"All\"]['Ds_gammaveto_M_Correction']>=dM)][i],\n",
    "      ]\n",
    "\n",
    "factor = 1\n",
    "plt.hist(DataFrames[\"Signal\"][(DataFrames[\"Signal\"]['Ds_gammaveto_M_Correction']>=dM)][i], color=[\"#D62728\"], label=\"Signal\", histtype='step', density=Density, bins=Bins, alpha=1, range=Range, weights=factor*np.ones_like(DataFrames[\"Signal\"][(DataFrames[\"Signal\"]['Ds_gammaveto_M_Correction']>=dM)][i]), linewidth=1.5)\n",
    "plt.hist(data, color= [\"#007C91\", \"#4C6EB1\", \"#2E2E2E\"], label=labels, density=Density, stacked=Stacked, bins=Bins, alpha=1, histtype='step', linewidth=1.5, range=Range)\n",
    "# plt.axvspan(Range[0],0.15,color='gray',alpha=0.2)\n",
    "# plt.axvline(0.15,ls='--',color='gray')\n",
    "\n",
    "# Title\n",
    "#--------\n",
    "plt.title(r'$Electron \\; Assigned \\; Electron \\; Mass$', loc = \"left\")\n",
    "# plt.title(r'$\\bf Generic \\; Events$', loc = \"Right\")\n",
    "# Label\n",
    "#-------\n",
    "plt.ylabel(r'$Entries/(\\; {width:.2f}\\;MeV/c^2)$'.format(width = perBin))\n",
    "plt.xlabel(r'$\\Delta m(D_s^{+} - D^{0})\\;[GeV/c^{2}]$')\n",
    "# plt.yscale(\"log\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Define the veto cut\n",
    "cut_low = 0.142\n",
    "cut_high = 0.15\n",
    "veto_query = \"Ds_diff_D0pi <= @cut_low or Ds_diff_D0pi >= @cut_high\"\n",
    "\n",
    "# === Apply veto\n",
    "df_vetoed = DataFrames[\"All\"].query(veto_query)\n",
    "\n",
    "# === Select D*+ only (|Ds_mcPDG| == 413)\n",
    "df_dstarp = df_vetoed[df_vetoed[\"Ds_mcPDG\"].abs() == 413]\n",
    "\n",
    "# === Count e_genMotherPDG values\n",
    "print(df_dstarp[[\"e_mcPDG\",\"e_genMotherPDG\",\"D0_mcPDG\",\"D0_genMotherPDG\"]].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Settings ===\n",
    "cut_low = 0.142\n",
    "cut_high = 0.15\n",
    "Bins = 50\n",
    "Range = (0.13, 0.2)\n",
    "var = \"Ds_diff_D0pi\"  # <== correct variable to match veto\n",
    "\n",
    "# === Select true D*+ events\n",
    "df = DataFrames[\"All\"]\n",
    "df_dstarp = df[df[\"Ds_mcPDG\"].abs() == 413]\n",
    "\n",
    "# === Inside and outside veto region (based on pion-mass Δm)\n",
    "inside = df_dstarp[(df_dstarp[var] > cut_low) & (df_dstarp[var] < cut_high)]\n",
    "outside = df_dstarp[(df_dstarp[var] <= cut_low) | (df_dstarp[var] >= cut_high)]\n",
    "\n",
    "# === Print stats\n",
    "total = len(df_dstarp)\n",
    "n_inside = len(inside)\n",
    "n_outside = len(outside)\n",
    "print(f\"Total D*⁺ events:      {total}\")\n",
    "print(f\"Inside veto region:   {n_inside} ({n_inside/total:.2%})\")\n",
    "print(f\"Outside veto region:  {n_outside} ({n_outside/total:.2%})\")\n",
    "\n",
    "# === Plot Ds_diff_D0pi\n",
    "bins = np.linspace(Range[0], Range[1], Bins + 1)\n",
    "\n",
    "# plt.figure(figsize=(8, 5))\n",
    "plt.hist(inside[var], bins=bins, histtype='step', linewidth=2, color=\"#D1495B\", density=True, label=\"Inside veto region\")\n",
    "plt.hist(outside[var], bins=bins, histtype='step', linewidth=2, color=\"#007C91\", density=True, label=\"Outside veto region\")\n",
    "plt.axvspan(cut_low, cut_high, color='gray', alpha=0.2, label=\"Veto Window\")\n",
    "\n",
    "plt.xlabel(r'$\\Delta m_{\\pi}(D_s^{+} - D^{0})\\;[GeV/c^{2}]$')\n",
    "plt.ylabel(\"Entries\")\n",
    "plt.title(\"Δm(π) for True D*⁺ Events\")\n",
    "plt.legend()\n",
    "# plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Settings ===\n",
    "cut_low = 0.142\n",
    "cut_high = 0.15\n",
    "Bins = 50\n",
    "Range = (0.0, 0.7)  # Range for e_p, not Δm\n",
    "var = \"Ds_diff_D0pi\"\n",
    "\n",
    "# === Select true D*+ events\n",
    "df = DataFrames[\"All\"]\n",
    "df_dstarp = df[df[\"Ds_mcPDG\"].abs() == 413]\n",
    "\n",
    "# === Inside and outside veto region (based on pion-mass Δm)\n",
    "inside = df_dstarp[(df_dstarp[var] > cut_low) & (df_dstarp[var] < cut_high)]\n",
    "outside = df_dstarp[(df_dstarp[var] <= cut_low) | (df_dstarp[var] >= cut_high)]\n",
    "\n",
    "# === Print stats\n",
    "total = len(df_dstarp)\n",
    "n_inside = len(inside)\n",
    "n_outside = len(outside)\n",
    "print(f\"Total D*⁺ events:      {total}\")\n",
    "print(f\"Inside veto region:   {n_inside} ({n_inside/total:.2%})\")\n",
    "print(f\"Outside veto region:  {n_outside} ({n_outside/total:.2%})\")\n",
    "\n",
    "# === Plot electron momentum (e_p)\n",
    "bins = np.linspace(Range[0], Range[1], Bins + 1)\n",
    "\n",
    "# plt.figure(figsize=(8, 5))\n",
    "plt.hist(inside[\"e_p\"], bins=bins, histtype='step', linewidth=2, color=\"#D1495B\", density=True, label=\"Inside veto region\")\n",
    "plt.hist(outside[\"e_p\"], bins=bins, histtype='step', linewidth=2, color=\"#007C91\", density=True, label=\"Outside veto region\")\n",
    "\n",
    "plt.xlabel(r'$p_e \\; [\\mathrm{GeV}/c]$')\n",
    "plt.ylabel(\"Normalized Entries\")\n",
    "plt.title(\"Electron Momentum for True D*⁺ Events\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # === Settings ===\n",
    "# cut_low = 0.142\n",
    "# cut_high = 0.15\n",
    "# Bins = 50\n",
    "# dm_var = \"Ds_diff_D0pi\"\n",
    "\n",
    "# # === DataFrames ===\n",
    "# df_sig = DataFrames[\"Signal\"]\n",
    "# df_all = DataFrames[\"All\"]\n",
    "\n",
    "# # === Restrict All to only D*+ truth-matched events\n",
    "# df_dstarp = df_all[df_all[\"Ds_mcPDG\"].abs() == 413]\n",
    "\n",
    "# # === Define veto categories for D*+ only\n",
    "# inside_mask = (df_dstarp[dm_var] > cut_low) & (df_dstarp[dm_var] < cut_high)\n",
    "# outside_mask = ~inside_mask\n",
    "\n",
    "# # === Variable list ===\n",
    "# variables_to_plot = [\n",
    "#     'e_chi2','e_ndf','e_trackTime','e_pionID','e_electronID','e_binaryPID_11_211','e_omega',\n",
    "#     'e_daughter_0_isCloneTrack','e_flightTime','e_formula_E_p','e_mcVirtual','e_isMisidentified',\n",
    "#     'e_ImpactXY','e_cos_theta','e_phi','e_mcP','e_M','e_pt','e_E','e_p','e_px','e_py','e_pz','e_abs_pz',\n",
    "#     'e_isOrHasCloneTrack','e_charge','e_isCloneTrack','e_dr','e_dz','e_abs_dr','e_abs_dz','e_z0','e_d0',\n",
    "#     'e_pValue','e_firstCDCLayer','e_firstPXDLayer','e_firstSVDLayer','e_nPXDHits','e_nVXDHits',\n",
    "#     'e_nSVDHits','e_nCDCHits','e_inARICHAcceptance','e_inCDCAcceptance','e_inTOPAcceptance','e_mcE',\n",
    "#     'Ds_M_uncorrected','Ds_M_pi','Ds_massDifference_0','Ds_diff_D0pi','Ds_diff_D0K','Ds_diff_D0e_noVF',\n",
    "#     'Ds_diff_D0pi_noVF','Ds_diff_D0K_noVF','Ds_cos_theta_D0e_noVF','Ds_formula_diff_D0pi_massDifference_0',\n",
    "#     'Ds_InvMLambda','Ds_Mode1Veto','Ds_Mode2Veto','Ds_DstarplusVeto','Ds_chiProb','Ds_useCMSFrame_p',\n",
    "#     'Ds_useCMSFrame_E','Ds_phi_diff','Ds_mcM','Ds_mcM_D0e_emass','Ds_mcM_D0e_pimass',\n",
    "#     'Ds_MminusMtrue_D0e_emass','Ds_MminusMtrue_D0e_pimass','Ds_decayAngle_0','Ds_cos_decayAngle_0',\n",
    "#     'Ds_decayAngle_1','Ds_cos_decayAngle_1','Ds_pointingAngle_0','Ds_daughterDiffOfPhi_0_1',\n",
    "#     'Ds_pointangle','Ds_daughterAngle_0_1','Ds_cos_daughterAngle_0_1','Ds_Angle_D0e','Ds_Angle_Ke',\n",
    "#     'Ds_Angle_pie','Ds_useCMSFrame_daughterAngle_0_1','Ds_useRestFrame_daughterAngle_0_1',\n",
    "#     'Ds_useDaughterRestFrame_daughterAngle_0_1_0_1','Ds_useDaughterRestFrame_daughterAngle_0_1_0_1_1',\n",
    "#     'Ds_psi','Ds_azimuthalAngleInDecayPlane_0_1','Ds_daughterDiffOf_0_1_cos_theta',\n",
    "#     'Ds_cosAngleBetweenMomentumAndVertexVector','Ds_cosAngleBetweenMomentumAndVertexVectorInXYPlane',\n",
    "#     'Ds_useRestFrame_daughterDiffOf_0_1_p','Ds_useRestFrame_daughterMotherDiffOf_0_p',\n",
    "#     'Ds_flightDistance','Ds_distance','Ds_daughterDiffOf_0_1_p','Ds_daughterDiffOf_0_1_E',\n",
    "#     'Ds_daughterDiffOf_0_1_px','Ds_daughterDiffOf_0_1_py','Ds_daughterDiffOf_0_1_pz',\n",
    "#     'Ds_daughterDiffOf_0_1_x','Ds_daughterDiffOf_0_1_y','Ds_daughterDiffOf_0_1_z',\n",
    "#     'Ds_daughterMotherDiffOf_0_p','Ds_daughterMotherDiffOf_0_E','Ds_daughterMotherDiffOf_0_px',\n",
    "#     'Ds_daughterMotherDiffOf_0_py','Ds_daughterMotherDiffOf_0_pz','Ds_daughterMotherDiffOf_0_x',\n",
    "#     'Ds_daughterMotherDiffOf_0_y','Ds_daughterMotherDiffOf_0_z','Ds_abs_daughterMotherDiffOf_0_distance',\n",
    "#     'Ds_L_diff','Ds_daughterMotherDiffOf_0_flightDistance','Ds_daughterMotherDiffOf_0_vertexDistance',\n",
    "#     'Ds_flightDistanceOfDaughter_0','Ds_gammaveto_M','Ds_gammaveto_M_Correction',\n",
    "#     'Ds_Dstar0Mode1_M','Ds_Dstar0Mode1_M_Correction','Ds_Dstar0Mode2_M_Correction',\n",
    "#     'Ds_Dstarplus_massDifference_Correction','Ds_Dstarplus_M_Correction','Ds_Ds_starminusDs',\n",
    "#     'Ds_Ds_starminusDs_M_Correction','Ds_goodDsplus','Ds_ImpactXY','Ds_cos_theta','Ds_phi','Ds_mcP',\n",
    "#     'Ds_M','Ds_pt','Ds_E','Ds_p','Ds_px','Ds_py','Ds_pz','Ds_abs_pz','Ds_isOrHasCloneTrack',\n",
    "#     'Ds_charge','Ds_mcE','D0_charged_product','D0_MomentumAsymmetry','D0_useCMSFrame_E',\n",
    "#     'D0_useCMSFrame_p','D0_dM','D0_useAlternativeDaughterHypothesis_M_1_K','D0_chiProb',\n",
    "#     'D0_cos_theta','D0_daughterAngle_0_1','D0_daughterDiffOf_0_1_theta','D0_daughterDiffOf_0_1_cos_theta',\n",
    "#     'D0_daughterDiffOf_0_1_phi','D0_daughterMotherDiffOf_0_theta','D0_daughterMotherDiffOf_0_cos_theta',\n",
    "#     'D0_daughterMotherDiffOf_0_phi','D0_decayAngle_0','D0_cos_decayAngle_0','D0_decayAngle_1',\n",
    "#     'D0_cos_decayAngle_1','D0_significanceOfDistance','D0_flightDistance','D0_useRestFrame_daughterAngle_0_1',\n",
    "#     'D0_formula_daughter_0_dr_daughter_1_dr','D0_formula_daughter_0_dz_daughter_1_dz','D0_ImpactXY',\n",
    "#     'D0_phi','D0_mcP','D0_M','D0_pt','D0_E','D0_p','D0_px','D0_py','D0_pz','D0_abs_pz'\n",
    "# ]\n",
    "\n",
    "# # === Loop and plot ===\n",
    "# for var in variables_to_plot:\n",
    "#     if var not in df_sig.columns or var not in df_dstarp.columns:\n",
    "#         continue\n",
    "#     if not np.issubdtype(df_sig[var].dtype, np.number) or np.issubdtype(df_sig[var].dtype, np.bool_):\n",
    "#         continue\n",
    "\n",
    "#     # Clean values\n",
    "#     sig_vals = df_sig[var].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "#     in_vals = df_dstarp.loc[inside_mask, var].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "#     out_vals = df_dstarp.loc[outside_mask, var].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "#     if len(sig_vals) < 10 or len(in_vals) < 10 or len(out_vals) < 10:\n",
    "#         continue\n",
    "\n",
    "#     # Smart range\n",
    "#     all_vals = np.concatenate([sig_vals, in_vals, out_vals])\n",
    "#     low = np.percentile(all_vals, 1)\n",
    "#     high = np.percentile(all_vals, 99)\n",
    "# #     bins = np.linspace(low, high, Bins)\n",
    "#     bins = np.linspace(-0.4, 0.4, Bins)\n",
    "\n",
    "#     # Plot\n",
    "#     plt.clf()\n",
    "#     plt.hist(sig_vals, bins=bins, histtype='step', label=\"Signal\", density=True, linewidth=2)\n",
    "#     plt.hist(in_vals, bins=bins, histtype='step', label=\"Inside veto (D*⁺)\", density=True, linewidth=2)\n",
    "#     plt.hist(out_vals, bins=bins, histtype='step', label=\"Outside veto (D*⁺)\", density=True, linewidth=2)\n",
    "#     plt.xlabel(var)\n",
    "#     plt.ylabel(\"Normalized Entries\")\n",
    "#     plt.title(f\"Comparison: {var}\")\n",
    "#     plt.legend()\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $D^{*+}$ BDT Cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut_low = 0.142\n",
    "# cut_high = 0.15\n",
    "\n",
    "# # Apply sideband cut to 'All' sample\n",
    "# DataFrames[\"All\"] = DataFrames[\"All\"][\n",
    "#     (DataFrames[\"All\"][\"Ds_diff_D0pi\"] <= cut_low) | (DataFrames[\"All\"][\"Ds_diff_D0pi\"] >= cut_high)\n",
    "# ]\n",
    "\n",
    "# # Apply sideband cut to each generator-level sample\n",
    "# for s in GenEvents:\n",
    "#     DataFrames[s] = DataFrames[s][\n",
    "#         (DataFrames[s][\"Ds_diff_D0pi\"] <= cut_low) | (DataFrames[s][\"Ds_diff_D0pi\"] >= cut_high)\n",
    "#     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrames[\"All\"][\"D0_isSignal\"] = DataFrames[\"All\"][\"D0_isSignal\"].replace(np.nan, 0)\n",
    "\n",
    "for s in GenEvents[0:]: # loop over samples\n",
    "    DataFrames[s][\"D0_isSignal\"] = DataFrames[s][\"D0_isSignal\"].replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrames[\"All\"][\"Ds_isSignal\"] = DataFrames[\"All\"][\"Ds_isSignal\"].replace(np.nan, 0)\n",
    "\n",
    "for s in GenEvents[0:]: # loop over samples\n",
    "    DataFrames[s][\"Ds_isSignal\"] = DataFrames[s][\"Ds_isSignal\"].replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fake $D^0$ BDT Cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrames[\"All\"] = DataFrames[\"All\"][(DataFrames[\"All\"][\"Ds_FakeD0BDT\"]>=0.556)]\n",
    "\n",
    "# for s in GenEvents[0:]: # loop over samples\n",
    "#     DataFrames[s] = DataFrames[s][(DataFrames[s][\"Ds_FakeD0BDT\"]>=0.556)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background Suppression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrames[samples[0]].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Signal Number: \",len(DataFrames[samples[0]]))\n",
    "print(\"Background Number: \",len(DataFrames[samples[1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('default')\n",
    "plt.rcParams.update({\n",
    "    \"axes.labelsize\": 14,\n",
    "    \"xtick.labelsize\": 12,\n",
    "    \"ytick.labelsize\": 12,\n",
    "    \"legend.fontsize\": 12,\n",
    "    \"figure.titlesize\": 16\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stacked = False\n",
    "Density = True\n",
    "Bins = 50\n",
    "Range = [0, 0.4]\n",
    "Op = -1\n",
    "dM = -1\n",
    "# i = \"Ds_gammaveto_M_Correction\"\n",
    "i = 'Ds_Ds_starminusDs_M_Correction'\n",
    "# i = 'Ds_extraInfo_FakeD0BDT'\n",
    "# i = 'Ds_chiProb'\n",
    "perBin = ((Range[1] - Range[0])/Bins)*1000\n",
    "# perBin = ((Range[1] - Range[0])/Bins)\n",
    "print(\"Width Per Bin: {width:.2f} MeV\".format(width = perBin))\n",
    "\n",
    "label1= r'$Signal$'\n",
    "label2= r'$Background$'\n",
    "\n",
    "labels=[label1,label2]\n",
    "colors=[\"#1f77b4\",\"#d62728\"]\n",
    "\n",
    "data = [\n",
    "        DataFrames[\"Signal\"][i], # (DataFrames[\"Signal\"]['Ds_charge']==-1) & \n",
    "        DataFrames[\"All\"][i]\n",
    "       ]\n",
    "\n",
    "\n",
    "plt.hist(data, color=colors, label=labels, alpha=1, range=Range, stacked=Stacked, density=Density, linewidth=2, bins=Bins, histtype='step')\n",
    "# plt.axvspan(Range[0],0.15,color='gray',alpha=0.2)\n",
    "# plt.axvline(0.58,ls='--',color='gray')\n",
    "\n",
    "# Title\n",
    "#---------\n",
    "# plt.title(r'$Signal: Charge(D_s^{+})=Positive$', loc = \"left\")\n",
    "# plt.title(r'$\\bf Signal\\;Events$', loc = \"right\")\n",
    "# plt.title(r'$\\int\\mathcal{L}dt\\approx\\;100$ fb$^{-1}$', loc = \"left\")\n",
    "# plt.title(r'$\\bf Generic\\;c\\bar{c}\\;Events$', loc = \"right\")\n",
    "# Label\n",
    "#---------\n",
    "plt.ylabel(r'$Entries/(\\; {width:.2f}\\;MeV/c^2)$'.format(width = perBin))\n",
    "# plt.ylabel(r'$Entries/(\\; {width:.2f}\\;)$'.format(width = perBin))\n",
    "# plt.xlabel(r'$m(e_{sig}^{+} e_{ROE}^{-})\\;[GeV/c^{2}]$')\n",
    "plt.xlabel(r'$\\Delta m(D_s^{*+} - D_{s}^{+})\\;[GeV/c^{2}]$')\n",
    "# plt.xlabel(r'$Fake \\; D^{0} \\; Suppression(D^{0})$')\n",
    "# plt.xlabel(r'$p-value_{IP}(D_{s}^{+})$')\n",
    "# plt.yscale(\"log\") \n",
    "# plt.xscale(\"log\") \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Variables = [\n",
    "            # \"Ds_FakeD0BDT\",\n",
    "            'Ds_chiProb',\n",
    "            'Ds_gammaveto_M_Correction',\n",
    "            'Ds_Ds_starminusDs_M_Correction',\n",
    "#             'e_omega'\n",
    "             ]\n",
    "\n",
    "features = [\n",
    "            # r'$Fake D^{0} Suppresion$',\n",
    "            r'$p-value_{IP}(D_{s}^{+})$',\n",
    "            r'$m(e_{sig}^{+} e_{ROE}^{-})$',\n",
    "            r'$\\Delta m(D_s^{*+} - D_{s}^{+})$',\n",
    "#             r'$\\omega (e)$'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 15))\n",
    "\n",
    "heatmap = sns.heatmap(DataFrames[\"Signal\"][Variables].corr(), annot=True, cmap=\"coolwarm\",vmin=-1, vmax=1)\n",
    "\n",
    "heatmap.set_title('Signal Correlation Heatmap', fontdict={'fontsize':20}, pad=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 15))\n",
    "\n",
    "heatmap = sns.heatmap(DataFrames[\"All\"][Variables].corr(), annot=True, cmap=\"coolwarm\",vmin=-1, vmax=1)\n",
    "\n",
    "heatmap.set_title('Background Correlation Heatmap', fontdict={'fontsize':20}, pad=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  Organise data ready for the machine learning model\n",
    "\n",
    "# # for sklearn data are usually organised\n",
    "# # into one 2D array of shape (n_samples x n_features)\n",
    "# # containing all the data and one array of categories\n",
    "# # of length n_samples\n",
    "\n",
    "# all_MC = []  # define empty list that will contain all features for the MC\n",
    "# for s in GenEvents:  # loop over the different samples\n",
    "#     if s != \"data\":  # only MC should pass this\n",
    "#         all_MC.append(\n",
    "#             DataFrames[s][Variables]\n",
    "#         )  # append the MC dataframe to the list containing all MC features\n",
    "# X = np.concatenate(\n",
    "#     all_MC\n",
    "# )  # concatenate the list of MC dataframes into a single 2D array of features, called X\n",
    "\n",
    "# all_y = (\n",
    "#     []\n",
    "# )  # define empty list that will contain labels whether an event in signal or background\n",
    "# for s in GenEvents:  # loop over the different samples\n",
    "#     if s != \"data\":  # only MC should pass this\n",
    "#         if \"Signal\" in s:  # only signal MC should pass this\n",
    "#             all_y.append(\n",
    "#                 np.ones(DataFrames[s].shape[0], dtype=np.int32)\n",
    "#             )  # signal events are labelled with 1\n",
    "#         else:  # only background MC should pass this\n",
    "#             all_y.append(\n",
    "#                 np.zeros(DataFrames[s].shape[0], dtype=np.int32)\n",
    "#             )  # background events are labelled 0\n",
    "# y = np.concatenate(\n",
    "#     all_y\n",
    "# )  # concatenate the list of labels into a single 1D array of labels, called y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Organize data for ML: features (X) and labels (y) ===\n",
    "\n",
    "all_MC = []  # list of all MC feature arrays\n",
    "all_y = []   # list of all MC label arrays\n",
    "\n",
    "for s in GenEvents:\n",
    "    if s == \"data\":\n",
    "        continue  # skip data\n",
    "\n",
    "    df = DataFrames[s]\n",
    "\n",
    "    if \"Signal\" in s:\n",
    "        # Use only true signal (Ds_isSignal == 1)\n",
    "        true_signal = df[df[\"Ds_isSignal\"] == 1]\n",
    "        all_MC.append(true_signal[Variables])\n",
    "        all_y.append(np.ones(true_signal.shape[0], dtype=np.int32))\n",
    "    else:\n",
    "        # All background MC\n",
    "        all_MC.append(df[Variables])\n",
    "        all_y.append(np.zeros(df.shape[0], dtype=np.int32))\n",
    "\n",
    "# Concatenate into final training arrays\n",
    "X = np.concatenate(all_MC)\n",
    "y = np.concatenate(all_y)\n",
    "\n",
    "#splitting with  Holdout method for eval_set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.30,\n",
    "                                                    random_state=42,\n",
    "                                                    # stratify=y\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()  # initialise StandardScaler\n",
    "\n",
    "# Fit only to the training data\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_scaled = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "Here is the step where we train the model.  There are a few things that need to be explained.  \n",
    "\n",
    "There are a couple of things implemented below called \"callbacks\".  Callback allow you to control how the learning is performed.  There are two callbacks used here.\n",
    "\n",
    "1. `ReduceLROnPlateau` is a callback that reduces the learning rate when the model training does not find an improvement in (this case) the validation loss after 5 epochs.  It reduces the learning rate by a factor of 0.2 down to a minimum of 0.00001.  This can help with problems like getting stuck in a local minimum.\n",
    "\n",
    "2. `EarlyStopping` stops the training after a certain number of epochs that you set (`patience`).  This helps reduce the chance of overfitting.  A rule of thumb is to set the patience to 10\\% the total number of epochs, though this really depends on you and your project.\n",
    "\n",
    "Callbacks are optional and you can remove or alter them here as you like.\n",
    "\n",
    "There is also the optional `validation_split` argument in the fit (train) function.  What this does is hold out a user-defined random portion of the training data at each epoch to perform a self-evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to torch tensors\n",
    "X_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)  # Make it (N, 1)\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Compute class weights for imbalance handling\n",
    "weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "pos_weight = torch.tensor([weights[0] / weights[1]], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryClassifier(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 8)\n",
    "        self.fc2 = nn.Linear(8, 4)\n",
    "        self.out = nn.Linear(4, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.out(x)  # Note: No sigmoid here — handled by loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BinaryClassifier(input_dim=X_tensor.shape[1])\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for xb, yb in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(xb)\n",
    "        loss = criterion(logits, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_loss = running_loss / len(dataloader)\n",
    "    print(f\"Epoch {epoch+1}/{n_epochs}, Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this cell if hiddenlayer is installed\n",
    "import hiddenlayer as hl\n",
    "\n",
    "# Pass a dummy batch to trace model\n",
    "dummy_input = X_tensor[:1]\n",
    "hl.build_graph(model, dummy_input).save(\"pytorch_model_diagram\", format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# === Track losses manually ===\n",
    "loss_history = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for xb, yb in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(xb)\n",
    "        loss = criterion(logits, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_loss = running_loss / len(dataloader)\n",
    "    loss_history.append(avg_loss)\n",
    "    print(f\"Epoch {epoch+1}/{n_epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# === Plotting loss curve ===\n",
    "history_df = pd.DataFrame({'loss': loss_history})\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "history_df.plot(ax=plt.gca(), linewidth=2)\n",
    "plt.ylim(bottom=0)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.title(\"Training Loss History\", fontsize=16)\n",
    "plt.xlabel(\"Epoch\", fontsize=14)\n",
    "plt.ylabel(\"Loss\", fontsize=14)\n",
    "plt.grid(False)\n",
    "\n",
    "# Save to file\n",
    "plt.savefig(\"Ds2D0enue_PyTorch_training_loss.png\", bbox_inches=\"tight\", pad_inches=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# === Predict probabilities ===\n",
    "y_proba = model.predict(X_test_scaled).flatten()  # gives values between 0 and 1\n",
    "\n",
    "# === Apply threshold to get binary prediction ===\n",
    "y_pred = (y_proba > 0.5).astype(int)\n",
    "\n",
    "# === Evaluate ===\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This optimization is pulling too much resources and ending the connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import pandas as pd\n",
    "\n",
    "results = []\n",
    "best_auc = 0\n",
    "best_model = None\n",
    "best_config = None\n",
    "\n",
    "# Grid search over architectures and learning rates\n",
    "for n_hidden in [1, 2, 3]:\n",
    "    for n_neurons in [4, 8, 16]:\n",
    "        for lr in [1e-3, 1e-2]:\n",
    "            print(f\"Training: n_hidden={n_hidden}, n_neurons={n_neurons}, learning_rate={lr}\")\n",
    "            model = build_model(\n",
    "                n_hidden=n_hidden,\n",
    "                n_neurons=n_neurons,\n",
    "                learning_rate=lr,\n",
    "                input_shape=[X_train_scaled.shape[1]]\n",
    "            )\n",
    "            history = model.fit(\n",
    "                X_train_scaled,\n",
    "                y_train,\n",
    "                epochs=30,\n",
    "                validation_split=0.2,\n",
    "                batch_size=64,\n",
    "                callbacks=my_callbacks,\n",
    "                class_weight=class_weights,\n",
    "                verbose=0\n",
    "            )\n",
    "            y_proba = model.predict(X_test_scaled).flatten()\n",
    "            fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "            auc_score = auc(fpr, tpr)\n",
    "            results.append((n_hidden, n_neurons, lr, auc_score))\n",
    "\n",
    "            # Save best model\n",
    "            if auc_score > best_auc:\n",
    "                best_auc = auc_score\n",
    "                best_model = model\n",
    "                best_config = (n_hidden, n_neurons, lr)\n",
    "\n",
    "# Save to DataFrame\n",
    "df_opt = pd.DataFrame(results, columns=[\"n_hidden\", \"n_neurons\", \"learning_rate\", \"AUC\"])\n",
    "\n",
    "# Show best result\n",
    "print(f\"Best config: n_hidden={best_config[0]}, n_neurons={best_config[1]}, learning_rate={best_config[2]}, AUC={best_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot only for a single learning rate (e.g. 1e-3) for heatmap simplicity\n",
    "pivot = df_opt[df_opt[\"learning_rate\"] == 1e-3].pivot(index=\"n_hidden\", columns=\"n_neurons\", values=\"AUC\")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(pivot, annot=True, cmap=\"viridis\", fmt=\".3f\")\n",
    "plt.title(\"AUC vs Hidden Layers and Neurons (lr=1e-3)\")\n",
    "plt.xlabel(\"Neurons per Layer\")\n",
    "plt.ylabel(\"Number of Hidden Layers\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "baseline_auc = roc_auc_score(y_test, best_model.predict(X_test_scaled).flatten())\n",
    "print(f\"Baseline AUC: {baseline_auc:.4f}\")\n",
    "\n",
    "importances = []\n",
    "\n",
    "for i, var in enumerate(features):\n",
    "    X_permuted = X_test_scaled.copy()\n",
    "    np.random.shuffle(X_permuted[:, i])  # permute one column at a time\n",
    "    y_pred_perm = best_model.predict(X_permuted).flatten()\n",
    "    perm_auc = roc_auc_score(y_test, y_pred_perm)\n",
    "    drop = baseline_auc - perm_auc\n",
    "    importances.append((var, drop))\n",
    "\n",
    "# Sort and plot\n",
    "importances.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "vars_sorted, drops = zip(*importances)\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.barh(vars_sorted, drops)\n",
    "plt.xlabel(\"AUC Drop After Permutation\")\n",
    "plt.title(\"Feature Importance via Permutation\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explainer assumes the model is Keras-based\n",
    "explainer = shap.DeepExplainer(best_model, X_train_scaled[:100])  # background samples\n",
    "shap_values = explainer.shap_values(X_test_scaled[:100])\n",
    "\n",
    "# Summary plot\n",
    "shap.summary_plot(shap_values[0], features=X_test_scaled[:100], feature_names=features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ks_2samp\n",
    "import numpy as np\n",
    "\n",
    "def get_pulls(counts, errors, pdf):\n",
    "    return (counts - pdf) / errors\n",
    "\n",
    "def compare_train_test_nn(model, X_train, y_train, X_test, y_test):\n",
    "    decisions = []\n",
    "\n",
    "    for X, y in ((X_train, y_train), (X_test, y_test)):\n",
    "        d1 = model.predict(X[y < 0.5]).flatten()  # background\n",
    "        d2 = model.predict(X[y > 0.5]).flatten()  # signal\n",
    "        decisions += [d1, d2]\n",
    "\n",
    "    lw = 3\n",
    "    fig, axs = plt.subplots(3, 1, figsize=(10, 10), gridspec_kw={'height_ratios': [1, 0.2, 0.2]})\n",
    "    bins = 50\n",
    "    bin_edges = np.linspace(0, 1, bins + 1)\n",
    "\n",
    "    test_bkg_count_weight = bins / len(decisions[2])\n",
    "    test_sig_count_weight = bins / len(decisions[3])\n",
    "    test_bkg_counts, test_bkg_bins = np.histogram(decisions[2], bins=bin_edges)\n",
    "    test_sig_counts, test_sig_bins = np.histogram(decisions[3], bins=bin_edges)\n",
    "\n",
    "    train_bkg_counts, _, _ = axs[0].hist(decisions[0], color='tab:blue',\n",
    "        histtype='step', bins=bin_edges, density=True, linewidth=lw, label='Train Background')\n",
    "    train_sig_counts, _, _ = axs[0].hist(decisions[1], color='tab:red',\n",
    "        histtype='step', bins=bin_edges, density=True, linewidth=lw, label='Train Signal')\n",
    "\n",
    "    axs[0].hist(decisions[0], color='tab:blue', histtype='stepfilled', alpha=0.4, bins=bin_edges, density=True)\n",
    "    axs[0].hist(decisions[1], color='tab:red', histtype='stepfilled', alpha=0.4, bins=bin_edges, density=True)\n",
    "\n",
    "    bin_width = bin_edges[1] - bin_edges[0]\n",
    "    bin_centers = bin_edges[:-1] + 0.5 * bin_width\n",
    "\n",
    "    axs[0].errorbar(bin_centers, test_bkg_count_weight * test_bkg_counts,\n",
    "        yerr=test_bkg_count_weight * np.sqrt(test_bkg_counts), label='Test Background',\n",
    "        color='tab:blue', marker='o', linewidth=lw, ls='')\n",
    "    axs[0].errorbar(bin_centers, test_sig_count_weight * test_sig_counts,\n",
    "        yerr=test_sig_count_weight * np.sqrt(test_sig_counts), label='Test Signal',\n",
    "        color='tab:red', marker='o', linewidth=lw, ls='')\n",
    "\n",
    "    axs[0].set_title(r'$D_{s}^{+} \\rightarrow D^{0} e^{+} \\nu_{e}$', loc='left')\n",
    "    axs[0].set_xlim(0, 1)\n",
    "    axs[0].set_ylim(0)\n",
    "    axs[0].set_ylabel('Event Density')\n",
    "\n",
    "    ks_sig = ks_2samp(decisions[1], decisions[3])[1]\n",
    "    ks_bkg = ks_2samp(decisions[0], decisions[2])[1]\n",
    "\n",
    "    leg = axs[0].legend(loc='upper center', title=f\"Sig K-S: {ks_sig:.3f}\\nBkg K-S: {ks_bkg:.3f}\")\n",
    "    leg._legend_box.align = \"left\"\n",
    "\n",
    "    pulls_bkg = get_pulls(test_bkg_count_weight * test_bkg_counts,\n",
    "                          test_bkg_count_weight * np.sqrt(test_bkg_counts),\n",
    "                          train_bkg_counts)\n",
    "    axs[1].bar(bin_centers, pulls_bkg, width=bin_width)\n",
    "    axs[1].set_xlim(0, 1)\n",
    "    axs[1].set_ylabel('Pulls')\n",
    "    axs[1].set_ylim(-5, 5)\n",
    "\n",
    "    pulls_sig = get_pulls(test_sig_count_weight * test_sig_counts,\n",
    "                          test_sig_count_weight * np.sqrt(test_sig_counts),\n",
    "                          train_sig_counts)\n",
    "    axs[2].bar(bin_centers, pulls_sig, width=bin_width, color='tab:red')\n",
    "    axs[2].set_xlim(0, 1)\n",
    "    axs[2].set_ylabel('Pulls')\n",
    "    axs[2].set_ylim(-5, 5)\n",
    "    axs[2].set_xlabel('NN Output')\n",
    "\n",
    "    return decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decisions = compare_train_test_nn(best_model, X_train_scaled, y_train, X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basf2 ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # compute ROC \n",
    "# sig_train=decisions[1]\n",
    "# sig_test=decisions[3]\n",
    "# bkg_train=decisions[0]\n",
    "# bkg_test=decisions[2]\n",
    "\n",
    "# bdt_cuts=np.linspace(0,1,100)\n",
    "# sig_efficiency_train=[]\n",
    "# bkg_rejection_train=[]\n",
    "# den_sig_train=len(sig_train)\n",
    "# den_bkg_train=len(bkg_train)\n",
    "\n",
    "# sig_efficiency_test=[]\n",
    "# bkg_rejection_test=[]\n",
    "# den_sig_test=len(sig_test)\n",
    "# den_bkg_test=len(bkg_test)\n",
    "\n",
    "\n",
    "# for cut in bdt_cuts:\n",
    "#     num_sig_train=len([el for el in sig_train if el>cut])\n",
    "#     num_bkg_train=len([el for el in bkg_train if el>cut])\n",
    "#     num_sig_test=len([el for el in sig_test if el>cut])\n",
    "#     num_bkg_test=len([el for el in bkg_test if el>cut])\n",
    "    \n",
    "#     sig_efficiency_test.append(num_sig_test/den_sig_test)\n",
    "#     bkg_rejection_test.append(1-(num_bkg_test/den_bkg_test))\n",
    "#     sig_efficiency_train.append(num_sig_train/den_sig_train)\n",
    "#     bkg_rejection_train.append(1-(num_bkg_train/den_bkg_train))\n",
    "\n",
    "# fig,axs=plt.subplots(1,1,figsize=(8,6))\n",
    "# lw=2\n",
    "# axs.plot([1, 0], [0, 1], color='grey', linestyle='--')\n",
    "# axs.plot(bkg_rejection_train,sig_efficiency_train,color='tab:blue',marker='',linewidth=lw,label='Train')\n",
    "# axs.plot(bkg_rejection_test,sig_efficiency_test,color='tab:red',marker='',linewidth=lw,ls='--',label='Test')\n",
    "# axs.set_title(r'$D_{s}^{+} \\rightarrow D^{0} e^{+} \\nu_{e}$',loc='left')\n",
    "\n",
    "# axs.set_ylim(0,1.05)\n",
    "# axs.set_xlim(0,1.05)\n",
    "# axs.legend(loc='lower left')\n",
    "# axs.set_xlabel('Background rejection')\n",
    "# axs.set_ylabel('Signal efficiency')\n",
    "# plt.tight_layout()\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import numpy as np\n",
    "\n",
    "# === NN Probabilities ===\n",
    "y_score_test = best_model.predict(X_test_scaled).flatten()\n",
    "fpr_test, tpr_test, thresholds_test = roc_curve(y_test, y_score_test)\n",
    "area_test = auc(fpr_test, tpr_test)\n",
    "\n",
    "y_score_train = best_model.predict(X_train_scaled).flatten()\n",
    "fpr_train, tpr_train, thresholds_train = roc_curve(y_train, y_score_train)\n",
    "area_train = auc(fpr_train, tpr_train)\n",
    "\n",
    "# === Separate signal and background scores ===\n",
    "sig_train = y_score_train[y_train == 1]\n",
    "bkg_train = y_score_train[y_train == 0]\n",
    "sig_test  = y_score_test[y_test == 1]\n",
    "bkg_test  = y_score_test[y_test == 0]\n",
    "\n",
    "# Group them if needed\n",
    "decisions = [bkg_train, sig_train, bkg_test, sig_test]\n",
    "\n",
    "# === Threshold Scan ===\n",
    "bdt_cuts = np.linspace(0, 1, 100)\n",
    "sig_eff_train, bkg_rej_train = [], []\n",
    "sig_eff_test, bkg_rej_test = [], []\n",
    "fom_vals = []\n",
    "\n",
    "for cut in bdt_cuts:\n",
    "    num_sig_train = np.sum(sig_train > cut)\n",
    "    num_bkg_train = np.sum(bkg_train > cut)\n",
    "    num_sig_test = np.sum(sig_test > cut)\n",
    "    num_bkg_test = np.sum(bkg_test > cut)\n",
    "\n",
    "    fom = num_sig_test / np.sqrt(num_sig_test + num_bkg_test) if (num_sig_test + num_bkg_test) > 0 else 0\n",
    "    fom_vals.append(fom)\n",
    "\n",
    "    sig_eff_train.append(num_sig_train / len(sig_train))\n",
    "    bkg_rej_train.append(1 - (num_bkg_train / len(bkg_train)))\n",
    "    sig_eff_test.append(num_sig_test / len(sig_test))\n",
    "    bkg_rej_test.append(1 - (num_bkg_test / len(bkg_test)))\n",
    "\n",
    "# === Optimal FoM ===\n",
    "fom_vals = np.array(fom_vals)\n",
    "best_idx = np.argmax(fom_vals)\n",
    "best_cut = bdt_cuts[best_idx]\n",
    "\n",
    "# === Plot ===\n",
    "fig, axs = plt.subplots(1, 1, figsize=(7, 6))\n",
    "lw = 2\n",
    "\n",
    "axs.plot(bkg_rej_train, sig_eff_train, color='tab:blue', linewidth=lw, label=f'Train (AUC = {area_train:.2f})')\n",
    "axs.plot(bkg_rej_test, sig_eff_test, color='tab:red', linestyle='--', linewidth=lw, label=f'Test (AUC = {area_test:.2f})')\n",
    "\n",
    "# Overfitting gap shading\n",
    "axs.fill_between(bkg_rej_test,\n",
    "                 sig_eff_train,\n",
    "                 sig_eff_test,\n",
    "                 where=(np.array(sig_eff_train) > np.array(sig_eff_test)),\n",
    "                 color='gray', alpha=0.2, label='Overfit Gap')\n",
    "\n",
    "# Best FoM cut\n",
    "axs.axhline(sig_eff_test[best_idx], color='black', ls='--', linewidth=1.6,\n",
    "            label=f'Best FoM Cut = {best_cut:.3f}')\n",
    "axs.axvline(bkg_rej_test[best_idx], color='black', ls='--', linewidth=1.6)\n",
    "axs.scatter(bkg_rej_test[best_idx], sig_eff_test[best_idx], color='green', s=50)\n",
    "\n",
    "# Labels\n",
    "axs.set_title(r'$D_{s}^{+} \\rightarrow D^{0} e^{+} \\nu_{e}$', loc='left')\n",
    "axs.set_ylim(0, 1.05)\n",
    "axs.set_xlim(0, 1.05)\n",
    "axs.set_xlabel('Background rejection')\n",
    "axs.set_ylabel('Signal efficiency')\n",
    "axs.legend(loc='lower left')\n",
    "axs.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learing ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# === Predict probabilities ===\n",
    "y_score_test = best_model.predict(X_test_scaled).flatten()\n",
    "fpr_test, tpr_test, thresholds_test = roc_curve(y_test, y_score_test)\n",
    "area_test = auc(fpr_test, tpr_test)\n",
    "\n",
    "y_score_train = best_model.predict(X_train_scaled).flatten()\n",
    "fpr_train, tpr_train, thresholds_train = roc_curve(y_train, y_score_train)\n",
    "area_train = auc(fpr_train, tpr_train)\n",
    "\n",
    "# === Plot ROC Curves ===\n",
    "plt.figure(figsize=(7, 6))\n",
    "plt.plot([0, 1], [0, 1], color='grey', linestyle='--', label='Random Classifier')\n",
    "plt.plot(fpr_test, tpr_test, label=f'Test ROC curve (AUC = {area_test:.2f})', color='tab:red')\n",
    "plt.plot(fpr_train, tpr_train, label=f'Train ROC curve (AUC = {area_train:.2f})', color='tab:blue')\n",
    "plt.xlim(0.0, 1.0)\n",
    "plt.ylim(0.0, 1.0)\n",
    "plt.xlabel('False Positive Rate', fontsize=14)\n",
    "plt.ylabel('True Positive Rate', fontsize=14)\n",
    "plt.title('ROC Curve: Train vs Test', fontsize=16)\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# === Predict probabilities ===\n",
    "y_pred_proba = best_model.predict(X_test_scaled).flatten()\n",
    "\n",
    "# === Compute ROC AUC ===\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"ROC AUC Score: {roc_auc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if XGBoost Is Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert training history to DataFrame\n",
    "history_df = pd.DataFrame(history.history)\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history_df[\"loss\"], label=\"Training Loss\", linewidth=2)\n",
    "plt.plot(history_df[\"val_loss\"], label=\"Validation Loss\", linewidth=2)\n",
    "plt.xlabel(\"Epoch\", fontsize=14)\n",
    "plt.ylabel(\"Loss\", fontsize=14)\n",
    "plt.title(\"Overfitting Check: Loss vs Epoch\", fontsize=16)\n",
    "plt.legend()\n",
    "plt.ylim(bottom=0)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy (if you're using it as a metric)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history_df[\"accuracy\"], label=\"Training Accuracy\", linewidth=2)\n",
    "plt.plot(history_df[\"val_accuracy\"], label=\"Validation Accuracy\", linewidth=2)\n",
    "plt.xlabel(\"Epoch\", fontsize=14)\n",
    "plt.ylabel(\"Accuracy\", fontsize=14)\n",
    "plt.title(\"Overfitting Check: Accuracy vs Epoch\", fontsize=16)\n",
    "plt.legend()\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BDT Cut Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fom_curve(scores, labels, weights=None, n_thresholds=200):\n",
    "    thresholds = np.linspace(0, 1, n_thresholds)\n",
    "    foms = []\n",
    "\n",
    "    for t in thresholds:\n",
    "        mask = scores > t\n",
    "        if weights is not None:\n",
    "            S = np.sum(weights[(labels == 1) & mask])\n",
    "            B = np.sum(weights[(labels == 0) & mask])\n",
    "        else:\n",
    "            S = np.sum((labels == 1) & mask)\n",
    "            B = np.sum((labels == 0) & mask)\n",
    "\n",
    "        fom = S / np.sqrt(S + B) if (S + B) > 0 else 0\n",
    "        foms.append(fom)\n",
    "\n",
    "    foms = np.array(foms)\n",
    "    best_idx = np.argmax(foms)\n",
    "    return thresholds, foms, thresholds[best_idx], foms[best_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict scores with best_model (use scaled test input)\n",
    "scores = best_model.predict(X_test_scaled).flatten()\n",
    "weights = np.ones_like(y_test)  # or use MC weights\n",
    "\n",
    "thresholds, foms, best_thresh, best_fom = compute_fom_curve(scores, y_test, weights=weights)\n",
    "\n",
    "print(f\"Best threshold: {best_thresh:.3f}\")\n",
    "print(f\"Best FoM: {best_fom:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(thresholds, foms)\n",
    "plt.axvline(best_thresh, color='red', linestyle='--', label=f'Best = {best_thresh:.3f}')\n",
    "plt.axvspan(0, best_thresh, color='gray', alpha=0.2)\n",
    "plt.xlabel(\"NN Output Threshold\")\n",
    "plt.ylabel(\"FoM = S / √(S + B)\")\n",
    "plt.title(\"FoM Scan vs NN Output Threshold\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale signal and all inputs\n",
    "df_signal_scaled = scaler.transform(DataFrames[\"Signal\"][Variables])\n",
    "df_all_scaled    = scaler.transform(DataFrames[\"All\"][Variables])\n",
    "\n",
    "# Predict scores with best_model\n",
    "DataFrames[\"Signal\"][\"Ds_BkgNN\"] = best_model.predict(df_signal_scaled).flatten()\n",
    "DataFrames[\"All\"][\"Ds_BkgNN\"]    = best_model.predict(df_all_scaled).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Functions import optimize_cut, plot_save\n",
    "\n",
    "cut = optimize_cut(\n",
    "    df_sig=DataFrames[\"Signal\"],                  # used for plotting signal vs background\n",
    "    df_bkg=DataFrames[\"All\"],\n",
    "    Signal=DataFrames[\"Signal\"],                  # used for FoM numerator (truth-matched signal)\n",
    "    Background=DataFrames[\"All\"],                 # used for FoM denominator (everything else)\n",
    "    var=\"Ds_BkgBDT\",                              # new classifier variable\n",
    "    FoM=\"Ds_BkgBDT\",                              # same as var here\n",
    "    xlabel=\"Background Classifier Output\",\n",
    "    Bins=50,\n",
    "    Range=[0, 1],\n",
    "    varmin=0,\n",
    "    varmax=0.99,\n",
    "    select=\"right\",                               # keep events with higher classifier output\n",
    "    Width=False,\n",
    "    query_signal=\"Ds_isSignal == 1\"\n",
    ")\n",
    "\n",
    "print(f\"Best cut is: {cut:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('default')\n",
    "plt.rcParams.update({\n",
    "    \"axes.labelsize\": 14,\n",
    "    \"xtick.labelsize\": 12,\n",
    "    \"ytick.labelsize\": 12,\n",
    "    \"legend.fontsize\": 12,\n",
    "    \"figure.titlesize\": 16\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(DataFrames[\"Signal\"][['Ds_isSignal']].value_counts(normalize=False,dropna=False).apply(lambda x: f\"{x:.6f}\"))\n",
    "print(DataFrames[\"Signal\"].query('Ds_BkgBDT>=0.455')[['Ds_isSignal']].value_counts(normalize=False,dropna=False).apply(lambda x: f\"{x:.6f}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(DataFrames[\"All\"][['D0_isSignal']].value_counts(normalize=False,dropna=False).apply(lambda x: f\"{x:.6f}\"))\n",
    "print(DataFrames[\"All\"].query('Ds_BkgBDT>=0.455')[['D0_isSignal']].value_counts(normalize=False,dropna=False).apply(lambda x: f\"{x:.6f}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stacked = False\n",
    "Density = False\n",
    "Bins = 50\n",
    "var = 'D0_dM'\n",
    "Range = [-0.02, 0.02]\n",
    "BD = 0.657\n",
    "perBin = ((Range[1] - Range[0])/Bins)*1000\n",
    "print(\"Width Per Bin: {width:.2f} MeV\".format(width = perBin))\n",
    "\n",
    "# label1= r'$Other$'\n",
    "label1= r'$Other \\; (FDS \\; BDT \\geq 0.8)$'\n",
    "\n",
    "labels=[label1]\n",
    "colors = ['C5']\n",
    "data=[\n",
    "      DataFrames[\"All\"][((abs(DataFrames[\"All\"]['Ds_D0_Other'])==1) | ((abs(DataFrames[\"All\"]['D0_mcPDG'])==421) & (abs(DataFrames[\"All\"]['D0_isSignal'])==0))) & (DataFrames[\"All\"][\"Ds_FakeD0BDT\"]>=BD)][var],\n",
    "      ]\n",
    "\n",
    "plt.hist(data, color=colors, label=labels, density=Density, stacked=Stacked, bins=Bins, alpha=1, histtype='step', linewidth=1.5, range=Range)\n",
    "# plt.axvspan(0.02,0.04,color='gray',alpha=0.2)\n",
    "# plt.axvline(0.02,ls='--',color='gray')\n",
    "# plt.axvline(0.04,ls='--',color='gray')\n",
    "\n",
    "# Title\n",
    "#--------\n",
    "plt.title(r'$\\bf Generic \\; Events$', loc = \"left\")\n",
    "plt.title(r'$\\int\\mathcal{L}dt\\approx\\;200$ fb$^{-1}$', loc = \"right\")\n",
    "# Label\n",
    "#-------\n",
    "plt.ylabel(r'$Entries/(\\; {width:.2f}\\;MeV/c^2)$'.format(width = perBin))\n",
    "plt.xlabel(r'$m(D^{0}) - m_{PDG}(D^{0}) \\;[GeV/c^{2}]$')\n",
    "# plt.yscale(\"log\")\n",
    "# plt.xscale(\"log\")\n",
    "# plt.ylim(0, 500)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suggested Background Break-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacked = False\n",
    "# Density = False\n",
    "# Bins = 50\n",
    "# Range = [0.1, 0.6]\n",
    "# Op = 0.721\n",
    "# dM = -1\n",
    "# # i = 'e_cos_theta'\n",
    "# # i = 'Ds_vpho_CMS_daughterAngle'\n",
    "# i = 'Ds_diff_D0pi'\n",
    "# # i = 'Ds_chiProb_noIP'\n",
    "# # i = 'Ds_chiProb'\n",
    "# # i = 'Ds_extraInfo_FastBDT'\n",
    "# # i = 'D0_chiProb'\n",
    "# # i = 'Ds_Ds_starminusDs_M_Correction'\n",
    "# # i = \"Ds_gammaveto_M_Correction\"\n",
    "# # i = 'D0_chiProb'\n",
    "# # i = \"Ds_L_diff\"\n",
    "# # var = 'e_cos_theta'\n",
    "# # i = 'e_pt'\n",
    "# perBin = ((Range[1] - Range[0])/Bins)*1000\n",
    "# # perBin = ((Range[1] - Range[0])/Bins)\n",
    "# print(\"Width Per Bin: {width:.2f} MeV\".format(width = perBin))\n",
    "\n",
    "# label1= r'$D^{*+} \\rightarrow D^{0} \\pi^{+}$'\n",
    "# label3= r'$D^{0}$'\n",
    "# label4= r'$Other$'\n",
    "\n",
    "# labels1=[label1,label3,label4]\n",
    "# colors1=['C1','C2','C3']\n",
    "# data1=[\n",
    "#       DataFrames[\"ccbar\"][(abs(DataFrames[\"ccbar\"]['Ds_D0_Dstarplus'])==1) & (DataFrames[\"ccbar\"]['Ds_gammaveto_M_Correction']>=dM) & (DataFrames[\"ccbar\"][\"Ds_BkgBDT\"]>=Op)][i],\n",
    "#       DataFrames[\"ccbar\"][(abs(DataFrames[\"ccbar\"]['Ds_D0_NoDstarplusDstar0'])==1) & (DataFrames[\"ccbar\"]['Ds_gammaveto_M_Correction']>=dM) & (DataFrames[\"ccbar\"][\"Ds_BkgBDT\"]>=Op)][i],\n",
    "#       DataFrames[\"ccbar\"][(abs(DataFrames[\"ccbar\"]['Ds_D0_Other'])==1) & (DataFrames[\"ccbar\"]['Ds_gammaveto_M_Correction']>=dM) & (DataFrames[\"ccbar\"][\"Ds_BkgBDT\"]>=Op)][i],\n",
    "#       ]\n",
    "# labels2=[r'$D^{*0} \\; (Comb.)$',r'$D^{*0} \\; (Peak)$']\n",
    "# colors2=['C4','C5']\n",
    "# data2=[\n",
    "#       DataFrames[\"ccbar\"][(abs(DataFrames[\"ccbar\"]['Ds_mcPDG'])!=423) & (abs(DataFrames[\"ccbar\"]['Ds_D0_Dstar0'])==1) & (DataFrames[\"ccbar\"][\"Ds_BkgBDT\"]>=Op)][i],\n",
    "#       DataFrames[\"ccbar\"][(abs(DataFrames[\"ccbar\"]['Ds_mcPDG'])==423) & (abs(DataFrames[\"ccbar\"]['Ds_D0_Dstar0'])==1) & (DataFrames[\"ccbar\"][\"Ds_BkgBDT\"]>=Op)][i],\n",
    "#       ]\n",
    "\n",
    "# # factor = 0.1\n",
    "# # plt.hist(DataFrames[\"Signal\"][(DataFrames[\"Signal\"]['Ds_gammaveto_M_Correction']>=dM) & (DataFrames[\"Signal\"][\"Ds_BS\"]>=Op)][i], label=\"Signal\", histtype='step', density=Density, bins=Bins, alpha=1, range=Range, weights=factor*np.ones_like(DataFrames[\"Signal\"][(DataFrames[\"Signal\"]['Ds_gammaveto_M_Correction']>=dM) & (DataFrames[\"Signal\"][\"Ds_BS\"]>=Op)][i]), ls='--', linewidth=1.5)\n",
    "# plt.hist(data1, color=colors1, label=labels1, density=Density, stacked=Stacked, bins=Bins, alpha=1, histtype='step', linewidth=1.5, range=Range)\n",
    "# plt.hist(data2, color=colors2, label=labels2, density=Density, stacked=False, bins=Bins, alpha=1, histtype='step', linewidth=1.5, range=Range)\n",
    "# # plt.axvspan(Range[0],0.15,color='gray',alpha=0.2)\n",
    "# # plt.axvline(0.58,ls='--',color='gray')\n",
    "\n",
    "# # Title\n",
    "# #--------\n",
    "# plt.title(r'$BDT \\; \\geq 0.721$', loc = \"left\")\n",
    "# # Label\n",
    "# #-------\n",
    "# # plt.ylabel(r'$Entries/(\\; {width:.2f}\\;)$'.format(width = perBin))\n",
    "# # plt.ylabel(r'$Entries/(\\; {width:.2f}\\;MeV/c)$'.format(width = perBin))\n",
    "# plt.ylabel(r'$Entries/(\\; {width:.2f}\\;MeV/c^2)$'.format(width = perBin))\n",
    "# # plt.xlabel(r'$p_{t} (e^{+}) [GeV/c]$')\n",
    "# # plt.xlabel(r'$\\Delta \\theta(D_s^{+} \\; K^{+/-}/K_{s}^{0}) \\; [rad]$')\n",
    "# # plt.xlabel(r'$cos\\theta \\; (e^{+})$')\n",
    "# # plt.xlabel(r'$p-value(D^{0})$')\n",
    "# # plt.xlabel(r'$p-value(D_{s}^{+})$')\n",
    "# # plt.xlabel(r'$p-value_{IP}(D_{s}^{+})$')\n",
    "# # plt.xlabel(r'$Fake D^{0} Suppression(D^{0})$')\n",
    "# # plt.xlabel(r'$m(e_{sig}^{+} e_{ROE}^{-})\\;[GeV/c^{2}]$')\n",
    "# # plt.xlabel(r'$p_{t} \\; (e^{+})\\;[GeV/c]$')\n",
    "# plt.xlabel(r'$\\Delta m(D_s^{+} - D^{0})\\;[GeV/c^{2}]$')\n",
    "# # plt.xlabel(r'$\\Delta m(D_s^{*+} - D_{s}^{+})\\;[GeV/c^{2}]$')\n",
    "# # plt.xlabel(r'$cos\\theta \\; (e^{+})$')\n",
    "# # plt.xlabel(r'$p-value(D^{0})$')\n",
    "# # plt.xlabel(r'$\\mid \\vec{x}_{D_{s}^{+}} - \\vec{x}_{D^{0}} \\mid \\; [cm]$')\n",
    "# # plt.xlabel(r'$dz \\; (e^{+}) \\; [cm]$')\n",
    "# # plt.yscale(\"log\")\n",
    "# # plt.xscale(\"log\")\n",
    "# # plt.ylim(0, 500)\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stacked = True\n",
    "Density = False\n",
    "Bins = 50\n",
    "# var = 'Ds_diff_D0pi'\n",
    "var = 'Ds_massDifference_0'\n",
    "Range = [0.0, 0.25]\n",
    "BS = 0.404\n",
    "Samples = \"All\"\n",
    "perBin = ((Range[1] - Range[0])/Bins)*1000\n",
    "print(\"Width Per Bin: {width:.2f} MeV\".format(width = perBin))\n",
    "\n",
    "label1= r'$Other$'\n",
    "label2= r'$Prompt \\; D^{0}$'\n",
    "label3= r'$D^{*0} \\rightarrow D^{0} X$'\n",
    "label4= r'$D^{*+} \\rightarrow D^{0} X$'\n",
    "\n",
    "labels=[label1,label2,label3,label4]\n",
    "colors=['C5','C4','C1','C2',]\n",
    "data=[\n",
    "      DataFrames[\"All\"][((DataFrames[\"All\"]['D0_isSignal'].isna()) | (abs(DataFrames[\"All\"]['D0_isSignal']) == 0)) & (DataFrames[Samples][\"Ds_BkgBDT\"]>=BS)][var],\n",
    "      DataFrames[\"All\"][((abs(DataFrames[\"All\"]['D0_genMotherPDG']) != 413) & (abs(DataFrames[\"All\"]['D0_genMotherPDG']) != 423)) & (abs(DataFrames[\"All\"]['D0_isSignal']) == 1) & (DataFrames[\"All\"][\"Ds_BkgBDT\"]>=BS)][var],\n",
    "      DataFrames[\"All\"][(abs(DataFrames[\"All\"]['D0_genMotherPDG']) == 423) & (abs(DataFrames[\"All\"]['D0_isSignal']) == 1) & (DataFrames[\"All\"][\"Ds_BkgBDT\"]>=BS)][var],\n",
    "      DataFrames[\"All\"][(abs(DataFrames[\"All\"]['D0_genMotherPDG']) == 413) & (abs(DataFrames[\"All\"]['D0_isSignal']) == 1) & (DataFrames[\"All\"][\"Ds_BkgBDT\"]>=BS)][var],\n",
    "      ]\n",
    "\n",
    "# factor = 0.7\n",
    "# plt.hist(DataFrames[\"Signal\"][(DataFrames[\"Signal\"][\"Ds_BkgBDT\"]>=BS)][var], label=\"Signal\", histtype='step', density=Density, bins=Bins, alpha=1, range=Range, weights=factor*np.ones_like(DataFrames[\"Signal\"][(DataFrames[\"Signal\"][\"Ds_BkgBDT\"]>=BS)][var]), ls='--', linewidth=1.5)\n",
    "plt.hist(data, color=colors, label=labels, density=Density, stacked=Stacked, bins=Bins, alpha=1, histtype='step', linewidth=2, range=Range)\n",
    "# plt.axvspan(Range[0],0.16,color='gray',alpha=0.2)\n",
    "# plt.axvline(0.16,ls='--',color='gray')\n",
    "\n",
    "# Title\n",
    "#--------\n",
    "# plt.title(r'$\\bf Generic \\; Events$', loc = \"left\")\n",
    "plt.title(r'$\\bf Generic \\; Events$' + \"\\n\" + r\"$BDT \\geq 0.404$\", loc = \"left\")\n",
    "plt.title(r'$\\int\\mathcal{L}dt\\approx\\;1443.999$ fb$^{-1}$', loc = \"right\")\n",
    "# Label\n",
    "#-------\n",
    "plt.ylabel(r'$Entries/(\\; {width:.2f}\\;MeV/c^2)$'.format(width = perBin))\n",
    "plt.xlabel(r'$\\Delta m_{e}(D_s^{+} - D^{0})\\;[GeV/c^{2}]$')\n",
    "# plt.yscale(\"log\")\n",
    "# plt.xscale(\"log\")\n",
    "# plt.ylim(0, 30000)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stacked = True\n",
    "Density = False\n",
    "Bins = 50\n",
    "var = 'Ds_diff_D0pi'\n",
    "# var = 'Ds_massDifference_0'\n",
    "Range = [0.1, 0.4]\n",
    "BS = -1\n",
    "Samples = \"All\"\n",
    "perBin = ((Range[1] - Range[0])/Bins)*1000\n",
    "print(\"Width Per Bin: {width:.2f} MeV\".format(width = perBin))\n",
    "\n",
    "label1= r'$Other$'\n",
    "label2= r'$Prompt \\; D^{0}$'\n",
    "label3= r'$D^{*0} \\rightarrow D^{0} X$'\n",
    "label4= r'$D^{*+} \\rightarrow D^{0} X$'\n",
    "\n",
    "labels=[label1,label2,label3,label4]\n",
    "colors=['C5','C4','C1','C2',]\n",
    "data=[\n",
    "      DataFrames[\"All\"][((DataFrames[\"All\"]['D0_isSignal'].isna()) | (abs(DataFrames[\"All\"]['D0_isSignal']) == 0)) & (DataFrames[Samples][\"Ds_BkgBDT\"]>=BS)][var],\n",
    "      DataFrames[\"All\"][((abs(DataFrames[\"All\"]['D0_genMotherPDG']) != 413) & (abs(DataFrames[\"All\"]['D0_genMotherPDG']) != 423)) & (abs(DataFrames[\"All\"]['D0_isSignal']) == 1) & (DataFrames[\"All\"][\"Ds_BkgBDT\"]>=BS)][var],\n",
    "      DataFrames[\"All\"][(abs(DataFrames[\"All\"]['D0_genMotherPDG']) == 423) & (abs(DataFrames[\"All\"]['D0_isSignal']) == 1) & (DataFrames[\"All\"][\"Ds_BkgBDT\"]>=BS)][var],\n",
    "      DataFrames[\"All\"][(abs(DataFrames[\"All\"]['D0_genMotherPDG']) == 413) & (abs(DataFrames[\"All\"]['D0_isSignal']) == 1) & (DataFrames[\"All\"][\"Ds_BkgBDT\"]>=BS)][var],\n",
    "      ]\n",
    "\n",
    "# factor = 0.7\n",
    "# plt.hist(DataFrames[\"Signal\"][(DataFrames[\"Signal\"][\"Ds_BkgBDT\"]>=BS)][var], label=\"Signal\", histtype='step', density=Density, bins=Bins, alpha=1, range=Range, weights=factor*np.ones_like(DataFrames[\"Signal\"][(DataFrames[\"Signal\"][\"Ds_BkgBDT\"]>=BS)][var]), ls='--', linewidth=1.5)\n",
    "plt.hist(data, color=colors, label=labels, density=Density, stacked=Stacked, bins=Bins, alpha=1, histtype='step', linewidth=2, range=Range)\n",
    "# plt.axvspan(Range[0],0.16,color='gray',alpha=0.2)\n",
    "# plt.axvline(0.16,ls='--',color='gray')\n",
    "\n",
    "# Title\n",
    "#--------\n",
    "plt.title(r'$\\bf Generic \\; Events$', loc = \"left\")\n",
    "# plt.title(r'$\\bf Generic \\; Events$' + \"\\n\" + r\"$BDT \\geq 0.525$\", loc = \"left\")\n",
    "plt.title(r'$\\int\\mathcal{L}dt\\approx\\;1443.999$ fb$^{-1}$', loc = \"right\")\n",
    "# Label\n",
    "#-------\n",
    "plt.ylabel(r'$Entries/(\\; {width:.2f}\\;MeV/c^2)$'.format(width = perBin))\n",
    "plt.xlabel(r'$\\Delta m_{\\pi}(D_s^{+} - D^{0})\\;[GeV/c^{2}]$')\n",
    "# plt.yscale(\"log\")\n",
    "# plt.xscale(\"log\")\n",
    "plt.ylim(0, 10000)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stacked = True\n",
    "Density = False\n",
    "Bins = 50\n",
    "# i = 'Ds_diff_D0pi'\n",
    "i = 'Ds_massDifference_0'\n",
    "Range = [0.0, 0.25]\n",
    "BS = 0.5\n",
    "Op = -1\n",
    "dM = -1\n",
    "Hits = -1\n",
    "perBin = ((Range[1] - Range[0])/Bins)*1000\n",
    "print(\"Width Per Bin: {width:.2f} MeV\".format(width = perBin))\n",
    "\n",
    "label1= r'$Comb.$'\n",
    "label2= r'$NaN$'\n",
    "label3= r'$D^{*0}$'\n",
    "label4= r'$D^{*+} \\rightarrow D^{0} \\pi^{+}$'\n",
    "\n",
    "labels=[label1,label2,label3,label4]\n",
    "colors=[\"#DD8452\",\"#C44E52\",\"#55A868\",\"#4C72B0\"]\n",
    "data=[\n",
    "      DataFrames[\"All\"][((abs(DataFrames[\"All\"][\"Ds_mcPDG\"])!=413) & (abs(DataFrames[\"All\"][\"Ds_mcPDG\"])!=423) & (~DataFrames[\"All\"][\"Ds_mcPDG\"].isna())) & (DataFrames[\"All\"]['Ds_gammaveto_M_Correction']>=dM) & (DataFrames[\"All\"][\"Ds_BkgBDT\"]>=BS)][i],\n",
    "      DataFrames[\"All\"][(DataFrames[\"All\"][\"Ds_mcPDG\"].isna()) & (DataFrames[\"All\"]['Ds_gammaveto_M_Correction']>=dM) & (DataFrames[\"All\"][\"Ds_BkgBDT\"]>=BS)][i],\n",
    "      DataFrames[\"All\"][(abs(DataFrames[\"All\"][\"Ds_mcPDG\"])==423) & (DataFrames[\"All\"]['Ds_gammaveto_M_Correction']>=dM) & (DataFrames[\"All\"][\"Ds_BkgBDT\"]>=BS)][i],\n",
    "      DataFrames[\"All\"][(abs(DataFrames[\"All\"][\"Ds_mcPDG\"])==413) & (DataFrames[\"All\"]['Ds_gammaveto_M_Correction']>=dM) & (DataFrames[\"All\"][\"Ds_BkgBDT\"]>=BS)][i]\n",
    "      ]\n",
    "\n",
    "# factor = 0.5\n",
    "# plt.hist(DataFrames[\"Signal\"][(DataFrames[\"Signal\"]['Ds_gammaveto_M_Correction']>=dM) & (DataFrames[\"Signal\"]['e_nPXDHits']>Hits)][i], label=\"Signal\", histtype='step', density=Density, bins=Bins, alpha=1, range=Range, weights=factor*np.ones_like(DataFrames[\"Signal\"][(DataFrames[\"Signal\"]['Ds_gammaveto_M_Correction']>=dM)][i]), ls='--', linewidth=1.5)\n",
    "plt.hist(data, color=colors, label=labels, density=Density, stacked=Stacked, bins=Bins, alpha=1, histtype='step', linewidth=1.5, range=Range)\n",
    "# plt.axvspan(Range[0],0.15,color='gray',alpha=0.2)\n",
    "# plt.axvline(0.15,ls='--',color='gray')\n",
    "\n",
    "# Title\n",
    "#--------\n",
    "plt.title(r'$e^{+}$ mass hypothesis: pion', loc = \"left\")\n",
    "plt.title(r'$\\int\\mathcal{L}dt\\approx\\;1443.999$ fb$^{-1}$', loc = \"right\")\n",
    "# Label\n",
    "#-------\n",
    "plt.ylabel(r'$Entries/(\\; {width:.2f}\\;MeV/c^2)$'.format(width = perBin))\n",
    "plt.xlabel(r'$\\Delta m(D_s^{+} - D^{0})\\;[GeV/c^{2}]$')\n",
    "# plt.yscale(\"log\")\n",
    "# plt.xscale(\"log\")\n",
    "# plt.ylim(0, 30000)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bins=50\n",
    "Density = False\n",
    "Stacked = True\n",
    "Range = [0.0,0.25]\n",
    "BS = -1\n",
    "perBin = ((Range[1] - Range[0])/Bins)*1000\n",
    "# var = 'Ds_diff_D0pi'\n",
    "var = 'Ds_massDifference_0'\n",
    "print(\"Width Per Bin: {width:.2f} MeV\".format(width = perBin))\n",
    "\n",
    "label1= r'$isSignal(D_s^{+})=1$'\n",
    "label2= r'$isSignal(D_s^{+})=0$'\n",
    "label3= r'$NaN$'\n",
    "\n",
    "labels=[label1,label2,label3]\n",
    "colors=['#7eb0d5','#fd7f6f','purple']\n",
    "\n",
    "data = [DataFrames[\"Signal\"][(DataFrames[\"Signal\"]['Ds_isSignal']==1) & (DataFrames[\"Signal\"][\"Ds_BkgBDT\"]>=BS)][var],\n",
    "        DataFrames[\"Signal\"][(DataFrames[\"Signal\"]['Ds_isSignal']==0) & (DataFrames[\"Signal\"][\"Ds_BkgBDT\"]>=BS)][var],\n",
    "        DataFrames[\"Signal\"][(DataFrames[\"Signal\"]['Ds_isSignal'].isna()) & (DataFrames[\"Signal\"][\"Ds_BkgBDT\"]>=BS)][var]\n",
    "       ]\n",
    "\n",
    "\n",
    "plt.hist(data[::-1], color=colors[::-1], label=labels[::-1], alpha=1, range=Range, linewidth=2, stacked=Stacked, density=Density, bins=Bins, histtype='step')\n",
    "# plt.axvspan(Range[0],0.16,color='gray',alpha=0.2)\n",
    "# plt.axvline(0.16,ls='--',color='gray')\n",
    "\n",
    "# Title\n",
    "#---------\n",
    "# Signal\n",
    "# plt.title(r'$2M\\;Events$', loc = \"left\")\n",
    "plt.title(r'$2M\\;Events$'+\"\\n\"+r\"$BDT \\geq 0.525$\", loc = \"left\")\n",
    "plt.title(r'$\\bf Signal\\;Events$', loc = \"right\")\n",
    "# # Background\n",
    "# plt.title(r'$\\int\\mathcal{L}dt\\approx\\;100$ fb$^{-1}$', loc = \"left\")\n",
    "# plt.title(r'$\\bf Generic\\;c\\bar{c}\\;Events$', loc = \"right\")\n",
    "# Label\n",
    "#---------\n",
    "plt.ylabel(r'$Entries/(\\; {width:.2f}\\;MeV/c^2)$'.format(width = perBin))\n",
    "plt.xlabel(r'$\\Delta m_{e}(D_s^{+} - D^{0})\\;[GeV/c^{2}]$')\n",
    "# plt.yscale(\"log\") \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Settings ===\n",
    "Stacked = True\n",
    "Density = False\n",
    "Bins = 50\n",
    "Range = [0.0, 0.25]\n",
    "BDT = 0.616\n",
    "perBin = ((Range[1] - Range[0]) / Bins) * 1000\n",
    "print(\"Width Per Bin: {:.2f} MeV\".format(perBin))\n",
    "\n",
    "# Data source and variables\n",
    "df = DataFrames[\"All\"][(DataFrames[\"All\"][\"Ds_BkgBDT\"]>=BDT)]\n",
    "cut_var = \"Ds_diff_D0pi\"\n",
    "plot_var = 'Ds_massDifference_0'\n",
    "pdg_var = 'Ds_mcPDG'\n",
    "\n",
    "# Sideband cut (exclude D*⁺ peak)\n",
    "cut_low = 0.142\n",
    "cut_high = 0.15\n",
    "df_cut = df.query(f\"{cut_var} <= @cut_low or {cut_var} >= @cut_high\")\n",
    "\n",
    "# === Categories based on true Ds_mcPDG ===\n",
    "dstar_plus = df_cut[abs(df_cut[pdg_var]) == 413][plot_var]\n",
    "dstar_zero = df_cut[abs(df_cut[pdg_var]) == 423][plot_var]\n",
    "other = df_cut[(abs(df_cut[pdg_var]) != 413) & (abs(df_cut[pdg_var]) != 423)][plot_var]\n",
    "\n",
    "# === Plot ===\n",
    "plt.hist([other, dstar_zero, dstar_plus],\n",
    "         color=[\"#2E2E2E\", \"#4C6EB1\", \"#007C91\"],\n",
    "         label=[\"Other\", r\"$D^{*0}$\", r\"$D^{*+}$\"],\n",
    "         density=Density,\n",
    "         stacked=Stacked,\n",
    "         bins=Bins,\n",
    "         range=Range,\n",
    "         histtype='step',\n",
    "         linewidth=2)\n",
    "\n",
    "# Titles and labels\n",
    "plt.title(r'$BDT \\geq 0.596$' + '\\n' +\n",
    "          r'$\\Delta m_{\\pi}(D_s^{+} - D^{0}) \\notin [0.142,\\; 0.15] \\; \\mathrm{GeV}/c^{2}$', loc=\"left\")\n",
    "plt.title(r'$\\int\\mathcal{L}dt\\approx\\;1444$ fb$^{-1}$', loc=\"right\")\n",
    "plt.xlabel(r'$\\Delta m_{e}(D_s^{+} - D^{0})\\;[GeV/c^{2}]$')\n",
    "plt.ylabel(r'$Entries/(\\;{:.2f}\\;MeV/c^2)$'.format(perBin))\n",
    "plt.legend()\n",
    "# plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Settings ===\n",
    "Stacked = True\n",
    "Density = False\n",
    "Bins = 50\n",
    "Range = [0.0, 0.25]\n",
    "BDT = 0.616\n",
    "perBin = ((Range[1] - Range[0]) / Bins) * 1000\n",
    "print(\"Width Per Bin: {:.2f} MeV\".format(perBin))\n",
    "\n",
    "# Data source and variables\n",
    "df = DataFrames[\"All\"][(DataFrames[\"All\"][\"Ds_BkgBDT\"] >= BDT)]\n",
    "cut_var = \"Ds_diff_D0pi\"\n",
    "plot_var = 'Ds_massDifference_0'\n",
    "pdg_var = 'Ds_mcPDG'\n",
    "\n",
    "# Sideband cut (exclude D*⁺ peak)\n",
    "cut_low = 0.142\n",
    "cut_high = 0.15\n",
    "df_cut = df.query(f\"{cut_var} <= @cut_low or {cut_var} >= @cut_high\")\n",
    "\n",
    "# === Categories based on true Ds_mcPDG ===\n",
    "dstar_plus  = df_cut[abs(df_cut[pdg_var]) == 413][plot_var]\n",
    "dstar_zero  = df_cut[abs(df_cut[pdg_var]) == 423][plot_var]\n",
    "other       = df_cut[(abs(df_cut[pdg_var]) != 413) & (abs(df_cut[pdg_var]) != 423)][plot_var]\n",
    "\n",
    "# === Plot ===\n",
    "plt.hist([other, dstar_plus, dstar_zero],\n",
    "         color=[\"#2E2E2E\", \"#007C91\", \"#4C6EB1\"],\n",
    "         label=[\"Other\", r\"$D^{*+}$\", r\"$D^{*0}$\"],\n",
    "         density=Density,\n",
    "         stacked=Stacked,\n",
    "         bins=Bins,\n",
    "         range=Range,\n",
    "         histtype='step',\n",
    "         linewidth=2)\n",
    "\n",
    "# Titles and labels\n",
    "plt.title(r'$BDT \\geq 0.616$' + '\\n' +\n",
    "          r'$\\Delta m_{\\pi}(D_s^{+} - D^{0}) \\notin [0.142,\\; 0.15] \\; \\mathrm{GeV}/c^{2}$', loc=\"left\")\n",
    "plt.title(r'$\\int\\mathcal{L}dt\\approx\\;1444$ fb$^{-1}$', loc=\"right\")\n",
    "plt.xlabel(r'$\\Delta m_{e}(D_s^{+} - D^{0})\\;[GeV/c^{2}]$')\n",
    "plt.ylabel(r'$Entries/(\\;{:.2f}\\;MeV/c^2)$'.format(perBin))\n",
    "plt.legend()\n",
    "# plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save BDT Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # === Output directory ===\n",
    "# output_dir = \"/group/belle2/users2022/amubarak/02-Grid/ML_Trained/\"\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# # === Base input path for original files ===\n",
    "# base_input_dir = \"/group/belle2/users2022/amubarak/02-Grid/Sample_Grid\"\n",
    "# Date = \"0526\"\n",
    "# Attempt = \"0\"\n",
    "\n",
    "# # === Save each DataFrame using original filename with _withBDT suffix ===\n",
    "# for s in samples:\n",
    "#     if s == \"Signal\":\n",
    "#         original_name = \"Ds2D0enu-Signal.root\"\n",
    "#         original_path = \"/home/belle2/amubarak/C01-Simulated_Events/\" + original_name\n",
    "#     else:\n",
    "#         original_name = f\"Ds2D0e-Generic_Ds_{Date}25_{Attempt}_{s}.root\"\n",
    "#         original_path = os.path.join(base_input_dir, original_name)\n",
    "\n",
    "#     # Strip .root and append _withBDT.root\n",
    "#     output_name = original_name.replace(\".root\", \"_withBDT.root\")\n",
    "#     out_path = os.path.join(output_dir, output_name)\n",
    "\n",
    "#     # Save to ROOT file\n",
    "#     with uproot.recreate(out_path) as f:\n",
    "#         f[\"Dstree\"] = DataFrames[s]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
